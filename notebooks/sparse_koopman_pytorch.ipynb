{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sparse Koopman Autoencoder (SKAE)\n",
        "\n",
        "**Self-contained notebook for Google Colab**\n",
        "\n",
        "This notebook implements Koopman operator learning for nonlinear dynamical systems using autoencoders with sparsity constraints. It includes:\n",
        "\n",
        "- **GenericKM**: Standard Koopman autoencoder with MLP encoder\n",
        "- **SparseKM**: Koopman autoencoder with L1 sparsity regularization  \n",
        "- **LISTAKM**: Learned Iterative Soft-Thresholding Algorithm (LISTA) based sparse encoder\n",
        "\n",
        "## Dynamical Systems\n",
        "\n",
        "| Environment | Dimension | Description |\n",
        "|------------|-----------|-------------|\n",
        "| `duffing` | 2D | Duffing oscillator with two stable centers |\n",
        "| `pendulum` | 2D | Simple pendulum |\n",
        "| `lotka_volterra` | 2D | Predator-prey dynamics |\n",
        "| `lorenz63` | 3D | Chaotic Lorenz attractor |\n",
        "| `parabolic` | 2D | Parabolic attractor (analytical Koopman) |\n",
        "| `lyapunov` | 2D | Multi-attractor system with Lyapunov dynamics |\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup & Installation\n",
        "\n",
        "Install required dependencies for Colab.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies (run once)\n",
        "%pip install torch matplotlib numpy scipy torchdiffeq --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports\n",
        "from __future__ import annotations\n",
        "import json\n",
        "from abc import ABC, abstractmethod\n",
        "from dataclasses import dataclass, field, asdict\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "from typing import Optional, Callable, Dict, Any, List, Sequence, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "try:\n",
        "    from torchdiffeq import odeint\n",
        "    HAS_TORCHDIFFEQ = True\n",
        "except ImportError:\n",
        "    HAS_TORCHDIFFEQ = False\n",
        "    print(\"torchdiffeq not available, using fallback RK4 integration\")\n",
        "\n",
        "try:\n",
        "    from scipy.spatial import Voronoi\n",
        "    HAS_SCIPY = True\n",
        "except ImportError:\n",
        "    HAS_SCIPY = False\n",
        "\n",
        "# Check device\n",
        "if torch.cuda.is_available():\n",
        "    DEVICE = 'cuda'\n",
        "    print(f\"Using CUDA: {torch.cuda.get_device_name(0)}\")\n",
        "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
        "    DEVICE = 'mps'\n",
        "    print(\"Using Apple Metal (MPS)\")\n",
        "else:\n",
        "    DEVICE = 'cpu'\n",
        "    print(\"Using CPU\")\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 2. Configuration System\n",
        "\n",
        "The configuration system uses Python dataclasses for type-safe, native Python configuration.\n",
        "\n",
        "### Available Configurations\n",
        "\n",
        "- `\"default\"`: Base configuration with minimal settings\n",
        "- `\"generic\"`: Standard KoopmanAE with MLP encoder (64-dim latent)\n",
        "- `\"generic_sparse\"`: KoopmanAE with L1 sparsity regularization. This is the main one that is used in the original notebook and for most of the experiments up till now.\n",
        "- `\"generic_prediction\"`: Prediction-focused (no reconstruction)\n",
        "- `\"lista\"`: LISTA-based sparse autoencoder (2048-dim latent)\n",
        "- `\"lista_nonlinear\"`: LISTA with nonlinear MLP encoder\n",
        "\n",
        "### Config Structure\n",
        "\n",
        "```\n",
        "Config\n",
        "├── SEED: int\n",
        "├── ENV: EnvConfig\n",
        "│   ├── ENV_NAME: str (system choice)\n",
        "│   └── <SYSTEM>: SystemConfig (dt, params)\n",
        "├── MODEL: ModelConfig\n",
        "│   ├── MODEL_NAME: str\n",
        "│   ├── TARGET_SIZE: int (latent dim)\n",
        "│   ├── Loss coefficients (RES_COEFF, RECONST_COEFF, etc.)\n",
        "│   ├── ENCODER: EncoderConfig\n",
        "│   └── DECODER: DecoderConfig\n",
        "└── TRAIN: TrainConfig\n",
        "    ├── NUM_STEPS: int (epochs)\n",
        "    ├── BATCH_SIZE: int\n",
        "    ├── LR: float\n",
        "    └── DATA_SIZE: int\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# CONFIGURATION SYSTEM (config.py)\n",
        "# =============================================================================\n",
        "\n",
        "@dataclass\n",
        "class ParabolicConfig:\n",
        "    \"\"\"Parabolic attractor system parameters.\"\"\"\n",
        "    LAMBDA: float = -1.0\n",
        "    MU: float = -0.1\n",
        "    DT: float = 0.1\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class DuffingConfig:\n",
        "    \"\"\"Duffing oscillator system parameters.\"\"\"\n",
        "    DT: float = 0.01\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class PendulumConfig:\n",
        "    \"\"\"Pendulum system parameters.\"\"\"\n",
        "    DT: float = 0.01\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class LotkaVolterraConfig:\n",
        "    \"\"\"Lotka-Volterra system parameters.\"\"\"\n",
        "    DT: float = 0.01\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Lorenz63Config:\n",
        "    \"\"\"Lorenz63 system parameters.\"\"\"\n",
        "    DT: float = 0.01\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class LyapunovConfig:\n",
        "    \"\"\"Lyapunov multi-attractor system parameters.\"\"\"\n",
        "    DT: float = 0.05\n",
        "    SIGMA: float = 0.5\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class EnvConfig:\n",
        "    \"\"\"Environment configuration.\"\"\"\n",
        "    ENV_NAME: str = \"duffing\"\n",
        "    PARABOLIC: ParabolicConfig = field(default_factory=ParabolicConfig)\n",
        "    DUFFING: DuffingConfig = field(default_factory=DuffingConfig)\n",
        "    PENDULUM: PendulumConfig = field(default_factory=PendulumConfig)\n",
        "    LOTKA_VOLTERRA: LotkaVolterraConfig = field(default_factory=LotkaVolterraConfig)\n",
        "    LORENZ63: Lorenz63Config = field(default_factory=Lorenz63Config)\n",
        "    LYAPUNOV: LyapunovConfig = field(default_factory=LyapunovConfig)\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class ListaConfig:\n",
        "    \"\"\"LISTA encoder-specific configuration.\"\"\"\n",
        "    NUM_LOOPS: int = 10\n",
        "    L: float = 1e3\n",
        "    ALPHA: float = 0.1\n",
        "    LINEAR_ENCODER: bool = False\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class EncoderConfig:\n",
        "    \"\"\"Encoder architecture configuration.\"\"\"\n",
        "    LAYERS: List[int] = field(default_factory=lambda: [16, 16])\n",
        "    LAST_RELU: bool = False\n",
        "    USE_BIAS: bool = False\n",
        "    ACTIVATION: str = \"relu\"  # from [\"relu\", \"tanh\", \"gelu\"]. could try other activations later on\n",
        "    LISTA: ListaConfig = field(default_factory=ListaConfig)\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class DecoderConfig:\n",
        "    \"\"\"Decoder architecture configuration.\"\"\"\n",
        "    LAYERS: List[int] = field(default_factory=list)\n",
        "    USE_BIAS: bool = False\n",
        "    ACTIVATION: str = \"relu\"\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class ModelConfig:\n",
        "    \"\"\"Model architecture and loss configuration.\"\"\"\n",
        "    MODEL_NAME: str = \"SparseKM\"  # from [\"GenericKM\", \"SparseKM\", \"LISTAKM\"]\n",
        "    NORM_FN: str = \"id\"  # from [\"id\", \"ball\"]\n",
        "    TARGET_SIZE: int = 16  # latent_dim i.e. zdim\n",
        "    \n",
        "    # Loss coefficients\n",
        "    RES_COEFF: float = 1.0  # alignment loss weight\n",
        "    RECONST_COEFF: float = 0.02  # reconstruction loss weight\n",
        "    PRED_COEFF: float = 0.0  # prediction loss weight\n",
        "    SPARSITY_COEFF: float = 1e-3  # sparsity loss weight (L1 regularization)\n",
        "    \n",
        "    ENCODER: EncoderConfig = field(default_factory=EncoderConfig)\n",
        "    DECODER: DecoderConfig = field(default_factory=DecoderConfig)\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class TrainConfig:\n",
        "    \"\"\"Training configuration.\"\"\"\n",
        "    NUM_STEPS: int = 2_000\n",
        "    BATCH_SIZE: int = 256\n",
        "    DATA_SIZE: int = 256 * 8\n",
        "    LR: float = 1e-4  # main learning rate (encoder/decoder)\n",
        "    WEIGHT_DECAY: float = 1e-4  # weight decay for AdamW optimizer\n",
        "    K_MATRIX_LR: float = 1e-5  # learning rate for Koopman matrix parameters\n",
        "    USE_SEQUENCE_LOSS: bool = False  # by default, we use single step loss\n",
        "    SEQUENCE_LENGTH: int = 10\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Config:\n",
        "    \"\"\"Main configuration container.\"\"\"\n",
        "    SEED: int = 0\n",
        "    ENV: EnvConfig = field(default_factory=EnvConfig)\n",
        "    MODEL: ModelConfig = field(default_factory=ModelConfig)\n",
        "    TRAIN: TrainConfig = field(default_factory=TrainConfig)\n",
        "    \n",
        "    def to_dict(self) -> dict:\n",
        "        return asdict(self)\n",
        "    \n",
        "    def to_json(self, filepath: str) -> None:\n",
        "        with open(filepath, 'w') as f:\n",
        "            json.dump(self.to_dict(), f, indent=2)\n",
        "    \n",
        "    @classmethod\n",
        "    def from_dict(cls, config_dict: dict) -> \"Config\":\n",
        "        env_dict = config_dict.get(\"ENV\", {})\n",
        "        env = EnvConfig(\n",
        "            ENV_NAME=env_dict.get(\"ENV_NAME\", \"duffing\"),\n",
        "            PARABOLIC=ParabolicConfig(**env_dict.get(\"PARABOLIC\", {})),\n",
        "            DUFFING=DuffingConfig(**env_dict.get(\"DUFFING\", {})),\n",
        "            PENDULUM=PendulumConfig(**env_dict.get(\"PENDULUM\", {})),\n",
        "            LOTKA_VOLTERRA=LotkaVolterraConfig(**env_dict.get(\"LOTKA_VOLTERRA\", {})),\n",
        "            LORENZ63=Lorenz63Config(**env_dict.get(\"LORENZ63\", {})),\n",
        "            LYAPUNOV=LyapunovConfig(**env_dict.get(\"LYAPUNOV\", {})),\n",
        "        )\n",
        "        \n",
        "        model_dict = config_dict.get(\"MODEL\", {})\n",
        "        encoder_dict = model_dict.get(\"ENCODER\", {})\n",
        "        lista = ListaConfig(**encoder_dict.get(\"LISTA\", {}))\n",
        "        encoder = EncoderConfig(**{k: v for k, v in encoder_dict.items() if k != \"LISTA\"})\n",
        "        encoder.LISTA = lista\n",
        "        decoder = DecoderConfig(**model_dict.get(\"DECODER\", {}))\n",
        "        \n",
        "        model = ModelConfig(**{k: v for k, v in model_dict.items() if k not in [\"ENCODER\", \"DECODER\"]})\n",
        "        model.ENCODER = encoder\n",
        "        model.DECODER = decoder\n",
        "        \n",
        "        train = TrainConfig(**config_dict.get(\"TRAIN\", {}))\n",
        "        \n",
        "        return cls(\n",
        "            SEED=config_dict.get(\"SEED\", 0),\n",
        "            ENV=env,\n",
        "            MODEL=model,\n",
        "            TRAIN=train\n",
        "        )\n",
        "    \n",
        "    @classmethod\n",
        "    def from_json(cls, filepath: str) -> \"Config\":\n",
        "        with open(filepath, 'r') as f:\n",
        "            config_dict = json.load(f)\n",
        "        return cls.from_dict(config_dict)\n",
        "\n",
        "\n",
        "def get_default_config() -> Config:\n",
        "    return Config()\n",
        "\n",
        "\n",
        "def get_train_generic_km_config() -> Config:\n",
        "    \"\"\"Training configuration for GenericKM (standard Koopman AE with MLP encoder).\"\"\"\n",
        "    cfg = Config()\n",
        "    cfg.TRAIN.LR = 1e-4\n",
        "    cfg.MODEL.MODEL_NAME = \"GenericKM\"\n",
        "    cfg.MODEL.TARGET_SIZE = 64\n",
        "    cfg.MODEL.NORM_FN = \"id\"\n",
        "    cfg.MODEL.DECODER.LAYERS = []\n",
        "    cfg.MODEL.ENCODER.LAYERS = [64, 64]\n",
        "    cfg.MODEL.SPARSITY_COEFF = 0.0\n",
        "    return cfg\n",
        "\n",
        "\n",
        "def get_train_generic_sparse_config() -> Config:\n",
        "    \"\"\"Training configuration for GenericKM with L1 regularization.\"\"\"\n",
        "    cfg = Config()\n",
        "    cfg.TRAIN.LR = 1e-4\n",
        "    cfg.MODEL.MODEL_NAME = \"GenericKM\"\n",
        "    cfg.MODEL.TARGET_SIZE = 64\n",
        "    cfg.MODEL.NORM_FN = \"id\"\n",
        "    cfg.MODEL.DECODER.LAYERS = []\n",
        "    cfg.MODEL.ENCODER.LAYERS = [64, 64]\n",
        "    cfg.MODEL.ENCODER.LAST_RELU = True\n",
        "    cfg.MODEL.ENCODER.USE_BIAS = True\n",
        "    cfg.MODEL.RECONST_COEFF = 0.5\n",
        "    cfg.MODEL.SPARSITY_COEFF = 0.01\n",
        "    return cfg\n",
        "\n",
        "\n",
        "def get_train_generic_prediction_config() -> Config:\n",
        "    \"\"\"Training configuration for prediction-focused KoopmanAE.\"\"\"\n",
        "    cfg = Config()\n",
        "    cfg.MODEL.MODEL_NAME = \"GenericKM\"\n",
        "    cfg.TRAIN.LR = 1e-3\n",
        "    cfg.MODEL.DECODER.LAYERS = []\n",
        "    cfg.MODEL.PRED_COEFF = 1.0\n",
        "    cfg.MODEL.RES_COEFF = 0.0\n",
        "    cfg.MODEL.RECONST_COEFF = 0.0\n",
        "    cfg.MODEL.SPARSITY_COEFF = 0.0\n",
        "    return cfg\n",
        "\n",
        "\n",
        "def get_train_lista_config() -> Config:\n",
        "    \"\"\"Configuration for LISTA-based Sparse KM.\"\"\"\n",
        "    cfg = Config()\n",
        "    cfg.MODEL.MODEL_NAME = \"LISTAKM\"\n",
        "    cfg.MODEL.ENCODER.LISTA.LINEAR_ENCODER = True\n",
        "    cfg.MODEL.ENCODER.LISTA.NUM_LOOPS = 10\n",
        "    cfg.MODEL.TARGET_SIZE = 1024 * 2\n",
        "    cfg.MODEL.RES_COEFF = 1.0\n",
        "    cfg.MODEL.RECONST_COEFF = 1.0\n",
        "    cfg.MODEL.PRED_COEFF = 0.0\n",
        "    cfg.MODEL.SPARSITY_COEFF = 1.0\n",
        "    cfg.MODEL.NORM_FN = \"id\"\n",
        "    cfg.MODEL.ENCODER.LISTA.L = 0.1\n",
        "    cfg.MODEL.ENCODER.LISTA.ALPHA = 5e-3\n",
        "    return cfg\n",
        "\n",
        "\n",
        "def get_train_lista_nonlinear_config() -> Config:\n",
        "    \"\"\"Training configuration for LISTA with nonlinear encoder.\"\"\"\n",
        "    cfg = Config()\n",
        "    cfg.MODEL.MODEL_NAME = \"LISTAKM\"\n",
        "    cfg.MODEL.ENCODER.LISTA.LINEAR_ENCODER = False\n",
        "    cfg.MODEL.ENCODER.LAYERS = [64, 64, 64]\n",
        "    cfg.MODEL.ENCODER.LISTA.NUM_LOOPS = 10\n",
        "    cfg.MODEL.TARGET_SIZE = 1024 * 2\n",
        "    cfg.MODEL.RES_COEFF = 1.0\n",
        "    cfg.MODEL.RECONST_COEFF = 1.0\n",
        "    cfg.MODEL.PRED_COEFF = 0.0\n",
        "    cfg.MODEL.SPARSITY_COEFF = 1.0\n",
        "    cfg.MODEL.NORM_FN = \"id\"\n",
        "    cfg.MODEL.ENCODER.LISTA.L = 1e4\n",
        "    cfg.MODEL.ENCODER.LISTA.ALPHA = 1.0\n",
        "    cfg.MODEL.ENCODER.LAST_RELU = True\n",
        "    cfg.MODEL.ENCODER.USE_BIAS = True\n",
        "    return cfg\n",
        "\n",
        "\n",
        "_TRAIN_CONFIG_REGISTRY = {\n",
        "    \"generic\": get_train_generic_km_config,\n",
        "    \"generic_sparse\": get_train_generic_sparse_config,\n",
        "    \"generic_prediction\": get_train_generic_prediction_config,\n",
        "    \"lista\": get_train_lista_config,\n",
        "    \"lista_nonlinear\": get_train_lista_nonlinear_config,\n",
        "}\n",
        "\n",
        "\n",
        "def get_config(name: str = \"default\") -> Config:\n",
        "    \"\"\"Get a named configuration.\n",
        "    \n",
        "    Args:\n",
        "        name: Configuration name. Options:\n",
        "            - \"default\": Base configuration\n",
        "            - \"generic\": Standard KoopmanMachine\n",
        "            - \"generic_sparse\": Sparse KoopmanMachine with L1\n",
        "            - \"generic_prediction\": Prediction-focused\n",
        "            - \"lista\": LISTA-based KoopmanMachine\n",
        "            - \"lista_nonlinear\": LISTA with MLP encoder\n",
        "    \n",
        "    Returns:\n",
        "        Config for the specified configuration.\n",
        "    \"\"\"\n",
        "    if name == \"default\":\n",
        "        return get_default_config()\n",
        "    if name not in _TRAIN_CONFIG_REGISTRY:\n",
        "        raise ValueError(f\"Unknown config name '{name}'. Available: {list(_TRAIN_CONFIG_REGISTRY.keys())}\")\n",
        "    return _TRAIN_CONFIG_REGISTRY[name]()\n",
        "\n",
        "\n",
        "print(\"✓ Configuration system loaded.\")\n",
        "print(f\"  Available configs: {list(_TRAIN_CONFIG_REGISTRY.keys())}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 3. Data: Dynamical Systems Environments\n",
        "\n",
        "This section defines the dynamical systems used for training and evaluation. Each system is implemented as an environment with:\n",
        "\n",
        "- `reset()`: Sample random initial conditions\n",
        "- `step()`: Advance the system by one timestep using RK4 integration\n",
        "\n",
        "### Implemented Systems\n",
        "\n",
        "This just follows the paper. The only added system not described in the paper is the Lyapunov Multi-Attractor system.\n",
        "\n",
        "1. **Duffing Oscillator**: Nonlinear oscillator with two stable centers\n",
        "2. **Pendulum**: Simple pendulum (angle, angular velocity)\n",
        "3. **Lotka-Volterra**: Predator-prey population dynamics\n",
        "4. **Lorenz 63**: Chaotic 3D system (butterfly effect)\n",
        "5. **Parabolic Attractor**: 2D system with analytical Koopman embedding\n",
        "6. **Lyapunov Multi-Attractor**: 2D system with 13 stable equilibria\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# DYNAMICAL SYSTEMS ENVIRONMENTS (data.py)\n",
        "# =============================================================================\n",
        "\n",
        "class Env(ABC):\n",
        "    \"\"\"Base Environment class for dynamical systems.\"\"\"\n",
        "\n",
        "    def __init__(self, cfg: Optional[Config] = None):\n",
        "        self.cfg = cfg\n",
        "\n",
        "    @abstractmethod\n",
        "    def reset(self, rng: Optional[torch.Generator] = None) -> torch.Tensor:\n",
        "        \"\"\"Reset environment to initial state.\"\"\"\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def step(self, state: torch.Tensor, action: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
        "        \"\"\"Take one step in the environment.\"\"\"\n",
        "        pass\n",
        "\n",
        "    @property\n",
        "    def observation_size(self) -> int:\n",
        "        \"\"\"Dimensionality of the state space.\"\"\"\n",
        "        rng = torch.Generator()\n",
        "        rng.manual_seed(0)\n",
        "        reset_state = self.unwrapped.reset(rng)\n",
        "        return reset_state.shape[-1]\n",
        "\n",
        "    @property\n",
        "    def action_size(self) -> int:\n",
        "        return 0\n",
        "\n",
        "    @property\n",
        "    def unwrapped(self) -> 'Env':\n",
        "        return self\n",
        "\n",
        "\n",
        "class Wrapper(Env):\n",
        "    \"\"\"Base Wrapper class for environment modifications.\"\"\"\n",
        "\n",
        "    def __init__(self, env: Env):\n",
        "        super().__init__(cfg=None)\n",
        "        self.env = env\n",
        "\n",
        "    def reset(self, rng: Optional[torch.Generator] = None) -> torch.Tensor:\n",
        "        return self.env.reset(rng)\n",
        "\n",
        "    def step(self, state: torch.Tensor, action: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
        "        return self.env.step(state, action)\n",
        "\n",
        "    @property\n",
        "    def observation_size(self) -> int:\n",
        "        return self.env.observation_size\n",
        "\n",
        "    @property\n",
        "    def action_size(self) -> int:\n",
        "        return self.env.action_size\n",
        "\n",
        "    @property\n",
        "    def unwrapped(self) -> Env:\n",
        "        return self.env.unwrapped\n",
        "\n",
        "\n",
        "class VectorWrapper(Wrapper):\n",
        "    \"\"\"Wrapper for vectorized/batched environment operations.\"\"\"\n",
        "\n",
        "    def __init__(self, env: Env, batch_size: int):\n",
        "        super().__init__(env)\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def reset(self, rng: Optional[torch.Generator] = None) -> torch.Tensor:\n",
        "        if rng is None:\n",
        "            rng = torch.Generator()\n",
        "        base_seed = rng.initial_seed()\n",
        "        states = []\n",
        "        for i in range(self.batch_size):\n",
        "            env_rng = torch.Generator().manual_seed(base_seed + i)\n",
        "            states.append(self.env.reset(env_rng))\n",
        "        return torch.stack(states, dim=0)\n",
        "\n",
        "    def step(self, state: torch.Tensor, action: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
        "        if action is None:\n",
        "            return torch.vmap(lambda s: self.env.step(s, None))(state)\n",
        "        else:\n",
        "            return torch.vmap(lambda s, a: self.env.step(s, a))(state, action)\n",
        "    \n",
        "    def generate_sequence_batch(\n",
        "        self, \n",
        "        rng: Optional[torch.Generator] = None,\n",
        "        window_length: int = 10,\n",
        "    ) -> torch.Tensor:\n",
        "        init_states = self.reset(rng)\n",
        "        trajectories = generate_trajectory(self.step, init_states, length=window_length)\n",
        "        sequences = torch.cat([init_states.unsqueeze(0), trajectories], dim=0)\n",
        "        return sequences.transpose(0, 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Integration utilities\n",
        "\n",
        "def integrate_euler(\n",
        "    x: torch.Tensor,\n",
        "    u: Optional[torch.Tensor],\n",
        "    dt: float,\n",
        "    dynamics_fn: Callable[[torch.Tensor, Optional[torch.Tensor]], torch.Tensor]\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"Euler integration step for ODE.\"\"\"\n",
        "    return x + dt * dynamics_fn(x, u)\n",
        "\n",
        "\n",
        "def integrate_rk4(\n",
        "    x: torch.Tensor,\n",
        "    u: Optional[torch.Tensor],\n",
        "    dt: float,\n",
        "    dynamics_fn: Callable[[torch.Tensor, Optional[torch.Tensor]], torch.Tensor]\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"Fourth-order Runge-Kutta (RK4) integration step for ODE.\"\"\"\n",
        "    k1 = dynamics_fn(x, u)\n",
        "    k2 = dynamics_fn(x + 0.5 * dt * k1, u)\n",
        "    k3 = dynamics_fn(x + 0.5 * dt * k2, u)\n",
        "    k4 = dynamics_fn(x + dt * k3, u)\n",
        "    return x + (dt / 6.0) * (k1 + 2.0 * k2 + 2.0 * k3 + k4)\n",
        "\n",
        "\n",
        "def generate_trajectory(\n",
        "    env_step: Callable[[torch.Tensor, Optional[torch.Tensor]], torch.Tensor],\n",
        "    init_state: torch.Tensor,\n",
        "    length: Optional[int] = None,\n",
        "    rng: Optional[torch.Generator] = None,\n",
        "    actions: Optional[torch.Tensor] = None\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"Generate a trajectory by repeatedly applying environment step.\"\"\"\n",
        "    if actions is None:\n",
        "        assert length is not None, \"Must provide either length or actions\"\n",
        "        states = []\n",
        "        state = init_state\n",
        "        for _ in range(length):\n",
        "            state = env_step(state)\n",
        "            states.append(state)\n",
        "        return torch.stack(states, dim=0)\n",
        "    else:\n",
        "        states = []\n",
        "        state = init_state\n",
        "        for action in actions:\n",
        "            state = env_step(state, action)\n",
        "            states.append(state)\n",
        "        return torch.stack(states, dim=0)\n",
        "\n",
        "\n",
        "def generate_sequence_window(\n",
        "    env_step: Callable[[torch.Tensor, Optional[torch.Tensor]], torch.Tensor],\n",
        "    init_state: torch.Tensor,\n",
        "    window_length: int,\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"Generate a sequence window including the initial state.\"\"\"\n",
        "    states = [init_state]\n",
        "    state = init_state\n",
        "    for _ in range(window_length):\n",
        "        state = env_step(state)\n",
        "        states.append(state)\n",
        "    return torch.stack(states, dim=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dynamical System Implementations\n",
        "\n",
        "class Pendulum(Env):\n",
        "    \"\"\"Pendulum model - freely swinging pole.\n",
        "    State: [angle, angular_velocity]\n",
        "    The angle x1 is measured in radians from the downward vertical position.\n",
        "    Initial conditions sampled uniformly from [-π, π] × [-2, 2].\n",
        "    \n",
        "    Dynamics:\n",
        "        dot(x1) = x2\n",
        "        dot(x2) = -(g/L) * sin(x1)\n",
        "    \"\"\"\n",
        "    def __init__(self, cfg: Config):\n",
        "        super().__init__(cfg)\n",
        "        self.g_over_l = 9.81 / 1.0\n",
        "        self.dt = cfg.ENV.PENDULUM.DT\n",
        "\n",
        "    @property\n",
        "    def action_size(self) -> int:\n",
        "        return 0\n",
        "\n",
        "    def reset(self, rng: Optional[torch.Generator] = None) -> torch.Tensor:\n",
        "        if rng is None:\n",
        "            rng = torch.Generator()\n",
        "        x1 = torch.empty(1).uniform_(-torch.pi, torch.pi, generator=rng)\n",
        "        x2 = torch.empty(1).uniform_(-2.0, 2.0, generator=rng)\n",
        "        return torch.tensor([x1.item(), x2.item()], dtype=torch.float32)\n",
        "\n",
        "    def step(self, state: torch.Tensor, action: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
        "        def dynamics_fn(state: torch.Tensor, action: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
        "            x1, x2 = state[0], state[1]\n",
        "            dx1 = x2\n",
        "            dx2 = -self.g_over_l * torch.sin(x1)\n",
        "            return torch.stack([dx1, dx2])\n",
        "        return integrate_rk4(state, None, self.dt, dynamics_fn)\n",
        "\n",
        "\n",
        "class Duffing(Env):\n",
        "    \"\"\"Duffing Oscillator - damped and force-driven particle model.\n",
        "    Nonlinear second-order ODE: x'' = x - x^3\n",
        "    \n",
        "    Admits two center points and an unstable fixed point at origin.\n",
        "    Initial conditions sampled uniformly from [-1.5, 1.5] × [-1, 1].\n",
        "    \n",
        "    Dynamics:\n",
        "        dot(x1) = x2\n",
        "        dot(x2) = x1 - x1^3\n",
        "    \"\"\"\n",
        "    def __init__(self, cfg: Config):\n",
        "        super().__init__(cfg)\n",
        "        self.dt = cfg.ENV.DUFFING.DT\n",
        "\n",
        "    @property\n",
        "    def action_size(self) -> int:\n",
        "        return 0\n",
        "\n",
        "    def reset(self, rng: Optional[torch.Generator] = None) -> torch.Tensor:\n",
        "        if rng is None:\n",
        "            rng = torch.Generator()\n",
        "        x1 = torch.empty(1).uniform_(-1.5, 1.5, generator=rng)\n",
        "        x2 = torch.empty(1).uniform_(-1.0, 1.0, generator=rng)\n",
        "        return torch.tensor([x1.item(), x2.item()], dtype=torch.float32)\n",
        "\n",
        "    def step(self, state: torch.Tensor, action: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
        "        def dynamics_fn(state: torch.Tensor, action: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
        "            x1, x2 = state[0], state[1]\n",
        "            dx1 = x2\n",
        "            dx2 = x1 - x1**3\n",
        "            return torch.stack([dx1, dx2])\n",
        "        return integrate_rk4(state, None, self.dt, dynamics_fn)\n",
        "\n",
        "\n",
        "class LotkaVolterra(Env):\n",
        "    \"\"\"Lotka-Volterra predator-prey model.\n",
        "    State: [prey_population, predator_population]\n",
        "    \"\"\"\n",
        "    def __init__(self, cfg: Config):\n",
        "        super().__init__(cfg)\n",
        "        self.alpha = 0.2\n",
        "        self.beta = 0.2\n",
        "        self.gamma = 0.2\n",
        "        self.delta = 0.2\n",
        "        self.dt = cfg.ENV.LOTKA_VOLTERRA.DT\n",
        "\n",
        "    @property\n",
        "    def action_size(self) -> int:\n",
        "        return 0\n",
        "\n",
        "    def reset(self, rng: Optional[torch.Generator] = None) -> torch.Tensor:\n",
        "        if rng is None:\n",
        "            rng = torch.Generator()\n",
        "        x1 = torch.empty(1).uniform_(0.02, 3.0, generator=rng)\n",
        "        x2 = torch.empty(1).uniform_(0.02, 3.0, generator=rng)\n",
        "        return torch.tensor([x1.item(), x2.item()], dtype=torch.float32)\n",
        "\n",
        "    def step(self, state: torch.Tensor, action: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
        "        def dynamics_fn(state: torch.Tensor, action: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
        "            prey, predator = state[0], state[1]\n",
        "            dx1 = self.alpha * prey - self.beta * prey * predator\n",
        "            dx2 = self.delta * prey * predator - self.gamma * predator\n",
        "            return torch.stack([dx1, dx2])\n",
        "        return integrate_rk4(state, None, self.dt, dynamics_fn)\n",
        "\n",
        "\n",
        "class Lorenz63(Env):\n",
        "    \"\"\"Lorenz 63 system - chaotic three-dimensional system.\"\"\"\n",
        "    def __init__(self, cfg: Config):\n",
        "        super().__init__(cfg)\n",
        "        self.sigma = 10.0\n",
        "        self.rho = 28.0\n",
        "        self.beta = 8.0 / 3.0\n",
        "        self.dt = cfg.ENV.LORENZ63.DT\n",
        "\n",
        "    @property\n",
        "    def action_size(self) -> int:\n",
        "        return 0\n",
        "\n",
        "    def reset(self, rng: Optional[torch.Generator] = None) -> torch.Tensor:\n",
        "        if rng is None:\n",
        "            rng = torch.Generator()\n",
        "        base_point = torch.tensor([0.0, 1.0, 1.05], dtype=torch.float32)\n",
        "        noise = torch.randn(3, generator=rng, dtype=torch.float32)\n",
        "        return base_point + noise\n",
        "\n",
        "    def step(self, state: torch.Tensor, action: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
        "        def dynamics_fn(state: torch.Tensor, action: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
        "            x, y, z = state[0], state[1], state[2]\n",
        "            dx = self.sigma * (y - x)\n",
        "            dy = x * (self.rho - z) - y\n",
        "            dz = x * y - self.beta * z\n",
        "            return torch.stack([dx, dy, dz])\n",
        "        return integrate_rk4(state, None, self.dt, dynamics_fn)\n",
        "\n",
        "\n",
        "class Parabolic(Env):\n",
        "    \"\"\"Parabolic Attractor - two-dimensional system with parabolic manifold.\"\"\"\n",
        "    def __init__(self, cfg: Config):\n",
        "        super().__init__(cfg)\n",
        "        self.const_lambda = cfg.ENV.PARABOLIC.LAMBDA\n",
        "        self.const_mu = cfg.ENV.PARABOLIC.MU\n",
        "        self.dt = cfg.ENV.PARABOLIC.DT\n",
        "\n",
        "    @property\n",
        "    def action_size(self) -> int:\n",
        "        return 0\n",
        "\n",
        "    def reset(self, rng: Optional[torch.Generator] = None) -> torch.Tensor:\n",
        "        if rng is None:\n",
        "            rng = torch.Generator()\n",
        "        x1 = torch.empty(1).uniform_(-1.0, 1.0, generator=rng)\n",
        "        x2 = torch.empty(1).uniform_(-1.0, 1.0, generator=rng)\n",
        "        return torch.tensor([x1.item(), x2.item()], dtype=torch.float32)\n",
        "\n",
        "    def step(self, state: torch.Tensor, action: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
        "        def dynamics_fn(state: torch.Tensor, action: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
        "            x1, x2 = state[0], state[1]\n",
        "            dx1 = self.const_mu * x1\n",
        "            dx2 = self.const_lambda * (x2 - x1**2)\n",
        "            return torch.stack([dx1, dx2])\n",
        "        return integrate_rk4(state, None, self.dt, dynamics_fn)\n",
        "\n",
        "\n",
        "class LyapunovMultiAttractor(Env):\n",
        "    \"\"\"Nonlinear 2D system with many exponentially stable equilibria.\"\"\"\n",
        "    def __init__(self, cfg: Config):\n",
        "        super().__init__(cfg)\n",
        "        self.dt = getattr(cfg.ENV, 'LYAPUNOV', None).DT if hasattr(cfg.ENV, 'LYAPUNOV') else 0.05\n",
        "        self.sigma = getattr(cfg.ENV, 'LYAPUNOV', None).SIGMA if hasattr(cfg.ENV, 'LYAPUNOV') else 0.5\n",
        "\n",
        "        self.points = torch.tensor([\n",
        "            [-1.0, -1.0], [ 1.0, -1.0], [-1.0,  1.0], [ 1.0,  1.0],\n",
        "            [ 0.0,  0.0],\n",
        "            [-1.0, -2.0], [ 1.0, -2.0], [-1.0,  2.0], [ 1.0,  2.0],\n",
        "            [-2.0, -1.0], [ 2.0, -1.0], [-2.0,  1.0], [ 2.0,  1.0],\n",
        "        ], dtype=torch.float32)\n",
        "        self._sigma2 = float(self.sigma) * float(self.sigma)\n",
        "\n",
        "    @property\n",
        "    def action_size(self) -> int:\n",
        "        return 0\n",
        "\n",
        "    def reset(self, rng: Optional[torch.Generator] = None) -> torch.Tensor:\n",
        "        if rng is None:\n",
        "            rng = torch.Generator()\n",
        "        x1 = torch.empty(1).uniform_(-2.5, 2.5, generator=rng)\n",
        "        x2 = torch.empty(1).uniform_(-2.5, 2.5, generator=rng)\n",
        "        return torch.tensor([x1.item(), x2.item()], dtype=torch.float32)\n",
        "\n",
        "    def step(self, state: torch.Tensor, action: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
        "        sigma2 = self._sigma2\n",
        "\n",
        "        def dynamics_fn(state: torch.Tensor, action: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
        "            diff = state.unsqueeze(0) - self.points\n",
        "            r2 = (diff * diff).sum(dim=1)\n",
        "            normx2 = torch.dot(state, state)\n",
        "            psi1 = normx2 * torch.exp(-r2 / sigma2)\n",
        "            term1 = (-2.0 / sigma2) * (psi1.unsqueeze(1) * diff).sum(dim=0)\n",
        "            psi2 = torch.exp(-r2 / sigma2)\n",
        "            term2 = -(psi2.unsqueeze(1) * diff).sum(dim=0)\n",
        "            return term1 + term2\n",
        "\n",
        "        return integrate_rk4(state, None, self.dt, dynamics_fn)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Environment Registry and Factory\n",
        "\n",
        "_ENV_REGISTRY = {\n",
        "    \"pendulum\": Pendulum,\n",
        "    \"duffing\": Duffing,\n",
        "    \"lotka_volterra\": LotkaVolterra,\n",
        "    \"lorenz63\": Lorenz63,\n",
        "    \"parabolic\": Parabolic,\n",
        "    \"lyapunov\": LyapunovMultiAttractor,\n",
        "}\n",
        "\n",
        "\n",
        "def make_env(cfg: Config) -> Env:\n",
        "    \"\"\"Factory function to create environment from configuration.\"\"\"\n",
        "    env_name = cfg.ENV.ENV_NAME\n",
        "    if env_name not in _ENV_REGISTRY:\n",
        "        raise ValueError(\n",
        "            f\"Unknown environment '{env_name}'. \"\n",
        "            f\"Available: {list(_ENV_REGISTRY.keys())}\"\n",
        "        )\n",
        "    return _ENV_REGISTRY[env_name](cfg)\n",
        "\n",
        "\n",
        "print(\"✓ Dynamical systems loaded.\")\n",
        "print(f\"  Available environments: {list(_ENV_REGISTRY.keys())}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 4. Koopman Autoencoder Models\n",
        "\n",
        "This section implements the Koopman autoencoder architectures:\n",
        "\n",
        "### Model Components\n",
        "\n",
        "- **MLPCoder**: Multi-layer perceptron for encoding/decoding\n",
        "- **LISTA**: Learned Iterative Soft-Thresholding Algorithm for sparse coding\n",
        "- **KoopmanMachine**: Abstract base class for Koopman operator learning\n",
        "\n",
        "### Concrete Implementations\n",
        "\n",
        "- **GenericKM**: Standard Koopman autoencoder with MLP encoder\n",
        "- **LISTAKM**: Koopman machine with LISTA sparse encoder\n",
        "\n",
        "### Key Concepts\n",
        "\n",
        "The Koopman operator is a linear operator that advances measurement functions forward in time through nonlinear system dynamics. The autoencoder learns:\n",
        "\n",
        "1. **Encoder** (phi): Maps observations x to latent space z = phi(x)\n",
        "2. **Koopman Matrix** (K): Linear dynamics in latent space z' = K @ z\n",
        "3. **Decoder** (psi): Maps latent representations back to observations x = psi(z)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# KOOPMAN AUTOENCODER MODELS (model.py)\n",
        "# =============================================================================\n",
        "\n",
        "def shrink(x: torch.Tensor, threshold: float) -> torch.Tensor:\n",
        "    \"\"\"Soft thresholding operator (shrinkage). Used in LISTA.\"\"\"\n",
        "    return torch.sign(x) * torch.maximum(torch.abs(x) - threshold, torch.zeros_like(x))\n",
        "\n",
        "\n",
        "def get_activation(name: str) -> nn.Module:\n",
        "    \"\"\"Get activation function by name.\"\"\"\n",
        "    activations = {\n",
        "        'relu': nn.ReLU(),\n",
        "        'tanh': nn.Tanh(),\n",
        "        'gelu': nn.GELU(),\n",
        "    }\n",
        "    if name not in activations:\n",
        "        raise ValueError(f\"Unknown activation '{name}'. Available: {list(activations.keys())}\")\n",
        "    return activations[name]\n",
        "\n",
        "\n",
        "class MLPCoder(nn.Module):\n",
        "    \"\"\"Multi-layer perceptron for encoding or decoding.\"\"\"\n",
        "    \n",
        "    def __init__(\n",
        "        self,\n",
        "        input_size: int,\n",
        "        target_size: int,\n",
        "        hidden_layers: List[int],\n",
        "        last_relu: bool = False,\n",
        "        use_bias: bool = False,\n",
        "        activation: str = 'relu'\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.input_size = input_size\n",
        "        self.target_size = target_size\n",
        "        self.hidden_layers = hidden_layers\n",
        "        self.last_relu = last_relu\n",
        "        \n",
        "        layers = []\n",
        "        prev_size = input_size\n",
        "        \n",
        "        for hidden_size in hidden_layers:\n",
        "            layers.append(nn.Linear(prev_size, hidden_size, bias=use_bias))\n",
        "            layers.append(get_activation(activation))\n",
        "            prev_size = hidden_size\n",
        "        \n",
        "        layers.append(nn.Linear(prev_size, target_size, bias=use_bias))\n",
        "        if last_relu:\n",
        "            layers.append(nn.ReLU())\n",
        "        \n",
        "        self.network = nn.Sequential(*layers)\n",
        "    \n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.network(x)\n",
        "\n",
        "\n",
        "class LISTA(nn.Module):\n",
        "    \"\"\"Learned Iterative Soft-Thresholding Algorithm (LISTA) encoder.\"\"\"\n",
        "    \n",
        "    def __init__(self, cfg: Config, xdim: int, Wd_init: torch.Tensor):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.xdim = xdim\n",
        "        self.zdim = cfg.MODEL.TARGET_SIZE\n",
        "        self.num_loops = cfg.MODEL.ENCODER.LISTA.NUM_LOOPS\n",
        "        self.alpha = cfg.MODEL.ENCODER.LISTA.ALPHA\n",
        "        self.L = cfg.MODEL.ENCODER.LISTA.L\n",
        "        self.use_linear_encode = cfg.MODEL.ENCODER.LISTA.LINEAR_ENCODER\n",
        "        \n",
        "        assert Wd_init.shape == (xdim, self.zdim), \\\n",
        "            f\"Wd_init shape {Wd_init.shape} doesn't match expected ({xdim}, {self.zdim})\"\n",
        "        \n",
        "        if self.use_linear_encode:\n",
        "            self.We = nn.Linear(xdim, self.zdim, bias=False)\n",
        "            with torch.no_grad():\n",
        "                self.We.weight.copy_((1.0 / self.L) * Wd_init.T)\n",
        "        else:\n",
        "            self.We = MLPCoder(\n",
        "                input_size=xdim,\n",
        "                target_size=self.zdim,\n",
        "                hidden_layers=cfg.MODEL.ENCODER.LAYERS,\n",
        "                use_bias=cfg.MODEL.ENCODER.USE_BIAS,\n",
        "                last_relu=cfg.MODEL.ENCODER.LAST_RELU,\n",
        "                activation=cfg.MODEL.ENCODER.ACTIVATION,\n",
        "            )\n",
        "        \n",
        "        S_init = torch.eye(self.zdim) - (1.0 / self.L) * (Wd_init.T @ Wd_init)\n",
        "        self.S = nn.Parameter(S_init)\n",
        "    \n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        nonsparse_code = self.We(x)\n",
        "        z = shrink(nonsparse_code, self.alpha / self.L)\n",
        "        for _ in range(self.num_loops):\n",
        "            z = shrink(z @ self.S + nonsparse_code, self.alpha / self.L)\n",
        "        return z\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Koopman Machine Base Class\n",
        "\n",
        "class KoopmanMachine(ABC, nn.Module):\n",
        "    \"\"\"Abstract base class for Koopman operator learning.\"\"\"\n",
        "    \n",
        "    def __init__(self, cfg: Config, observation_size: int):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.observation_size = observation_size\n",
        "        self.target_size = cfg.MODEL.TARGET_SIZE\n",
        "        self.dt = None\n",
        "    \n",
        "    @abstractmethod\n",
        "    def encode(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Encode observations to latent space.\"\"\"\n",
        "        pass\n",
        "    \n",
        "    @abstractmethod\n",
        "    def decode(self, y: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Decode latent representations to observation space.\"\"\"\n",
        "        pass\n",
        "    \n",
        "    @abstractmethod\n",
        "    def kmatrix(self) -> torch.Tensor:\n",
        "        \"\"\"Extract the learned Koopman matrix from parameters.\"\"\"\n",
        "        pass\n",
        "    \n",
        "    def residual(self, x: torch.Tensor, nx: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Compute alignment loss between consecutive states in latent space.\"\"\"\n",
        "        y = self.encode(x)\n",
        "        ny = self.encode(nx)\n",
        "        kmat = self.kmatrix()\n",
        "        return torch.norm(y @ kmat - ny, dim=-1)\n",
        "    \n",
        "    def reconstruction(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Reconstruction via encode-decode.\"\"\"\n",
        "        return self.decode(self.encode(x))\n",
        "    \n",
        "    def sparsity_loss(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Compute L1 sparsity loss on latent codes.\"\"\"\n",
        "        z = self.encode(x)\n",
        "        return torch.norm(z, p=1, dim=-1).mean()\n",
        "    \n",
        "    def step_latent(self, y: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Step forward in latent space using Koopman matrix.\"\"\"\n",
        "        kmat = self.kmatrix()\n",
        "        return y @ kmat\n",
        "    \n",
        "    def step_env(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Predict next observation using Koopman dynamics.\"\"\"\n",
        "        y = self.encode(x)\n",
        "        ny = self.step_latent(y)\n",
        "        nx = self.decode(ny)\n",
        "        return nx\n",
        "    \n",
        "    def koopman_ode_func(self, t: torch.Tensor, z: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"ODE function for continuous-time Koopman dynamics: dz/dt = K @ z.\"\"\"\n",
        "        kmat = self.kmatrix()\n",
        "        return z @ kmat\n",
        "    \n",
        "    def integrate_latent_ode(\n",
        "        self, \n",
        "        z0: torch.Tensor, \n",
        "        t_span: torch.Tensor,\n",
        "        method: str = 'dopri5'\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"Integrate Koopman dynamics from z0 over time points in t_span.\"\"\"\n",
        "        if not hasattr(self, '_printed_ode_method'):\n",
        "            if HAS_TORCHDIFFEQ:\n",
        "                print(f\"Using torchdiffeq with method '{method}' for ODE integration\")\n",
        "            else:\n",
        "                print(\"Using manual RK4 for ODE integration (torchdiffeq not available)\")\n",
        "            self._printed_ode_method = True\n",
        "        \n",
        "        if HAS_TORCHDIFFEQ:\n",
        "            z_traj = odeint(\n",
        "                self.koopman_ode_func,\n",
        "                z0,\n",
        "                t_span,\n",
        "                method=method,\n",
        "                rtol=1e-5,\n",
        "                atol=1e-7,\n",
        "            )\n",
        "            return z_traj\n",
        "        else:\n",
        "            return self._integrate_rk4_fallback(z0, t_span)\n",
        "    \n",
        "    def _integrate_rk4_fallback(\n",
        "        self, \n",
        "        z0: torch.Tensor, \n",
        "        t_span: torch.Tensor\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"Fallback RK4 integration when torchdiffeq is not available.\"\"\"\n",
        "        z_list = [z0]\n",
        "        z = z0\n",
        "        for i in range(len(t_span) - 1):\n",
        "            t = t_span[i]\n",
        "            dt = t_span[i+1] - t_span[i]\n",
        "            k1 = self.koopman_ode_func(t, z)\n",
        "            k2 = self.koopman_ode_func(t + 0.5 * dt, z + 0.5 * dt * k1)\n",
        "            k3 = self.koopman_ode_func(t + 0.5 * dt, z + 0.5 * dt * k2)\n",
        "            k4 = self.koopman_ode_func(t + dt, z + dt * k3)\n",
        "            z = z + (dt / 6.0) * (k1 + 2.0 * k2 + 2.0 * k3 + k4)\n",
        "            z_list.append(z)\n",
        "        return torch.stack(z_list, dim=0)\n",
        "    \n",
        "    def rollout_sequence_ode(\n",
        "        self,\n",
        "        x0: torch.Tensor,\n",
        "        num_steps: int,\n",
        "        dt: float,\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"Rollout a sequence using ODE integration of Koopman dynamics.\"\"\"\n",
        "        z0 = self.encode(x0)\n",
        "        t_span = torch.arange(num_steps + 1, dtype=torch.float32, device=x0.device) * dt\n",
        "        z_traj = self.integrate_latent_ode(z0, t_span)\n",
        "        num_times, batch_size, target_size = z_traj.shape\n",
        "        z_flat = z_traj.reshape(num_times * batch_size, target_size)\n",
        "        x_flat = self.decode(z_flat)\n",
        "        x_traj = x_flat.reshape(num_times, batch_size, self.observation_size)\n",
        "        return x_traj\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Loss functions for KoopmanMachine (continued)\n",
        "\n",
        "def _koopman_loss(\n",
        "    self: KoopmanMachine,\n",
        "    x: torch.Tensor,\n",
        "    nx: torch.Tensor\n",
        ") -> Tuple[torch.Tensor, Dict[str, torch.Tensor]]:\n",
        "    \"\"\"Compute total loss and metrics (single-step version).\"\"\"\n",
        "    kmat = self.kmatrix()\n",
        "    prediction = self.decode(self.encode(x) @ kmat)\n",
        "    prediction_loss = torch.norm(prediction - nx, dim=-1).mean()\n",
        "    \n",
        "    residual_loss = self.residual(x, nx).mean()\n",
        "    \n",
        "    reconst_loss = torch.norm(x - self.reconstruction(x), dim=-1).mean()\n",
        "    reconst_loss += torch.norm(nx - self.reconstruction(nx), dim=-1).mean()\n",
        "    \n",
        "    sparsity_loss = self.sparsity_loss(x)\n",
        "    sparsity_loss += self.sparsity_loss(nx)\n",
        "    sparsity_loss *= 0.5\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        kmat_device = kmat.device\n",
        "        if kmat_device.type == 'mps':\n",
        "            kmat_cpu = kmat.cpu()\n",
        "            eigvals = torch.linalg.eigvals(kmat_cpu)\n",
        "        else:\n",
        "            eigvals = torch.linalg.eigvals(kmat)\n",
        "        max_eigenvalue = torch.max(eigvals.real)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        z = self.encode(x)\n",
        "        num_nonzero_codes = (z != 0).float().sum(dim=-1).mean()\n",
        "        sparsity_ratio = 1.0 - num_nonzero_codes / self.target_size\n",
        "    \n",
        "    total_loss = (\n",
        "        self.cfg.MODEL.RES_COEFF * residual_loss +\n",
        "        self.cfg.MODEL.RECONST_COEFF * reconst_loss +\n",
        "        self.cfg.MODEL.PRED_COEFF * prediction_loss +\n",
        "        self.cfg.MODEL.SPARSITY_COEFF * sparsity_loss\n",
        "    )\n",
        "    \n",
        "    metrics = {\n",
        "        'loss': total_loss.item(),\n",
        "        'residual_loss': residual_loss.item(),\n",
        "        'reconst_loss': reconst_loss.item(),\n",
        "        'prediction_loss': prediction_loss.item(),\n",
        "        'sparsity_loss': sparsity_loss.item(),\n",
        "        'A_max_eigenvalue': max_eigenvalue.item(),\n",
        "        'sparsity_ratio': sparsity_ratio.item(),\n",
        "    }\n",
        "    \n",
        "    return total_loss, metrics\n",
        "\n",
        "\n",
        "def _koopman_loss_sequence(\n",
        "    self: KoopmanMachine,\n",
        "    x_seq: torch.Tensor,\n",
        "    dt: float,\n",
        ") -> Tuple[torch.Tensor, Dict[str, torch.Tensor]]:\n",
        "    \"\"\"Compute sequence-based loss using ODE integration.\"\"\"\n",
        "    batch_size, seq_len, obs_size = x_seq.shape\n",
        "    \n",
        "    x_flat = x_seq.reshape(batch_size * seq_len, obs_size)\n",
        "    z_flat = self.encode(x_flat)\n",
        "    z_seq = z_flat.reshape(batch_size, seq_len, self.target_size)\n",
        "    \n",
        "    x0 = x_seq[:, 0, :]\n",
        "    z0 = z_seq[:, 0, :]\n",
        "    \n",
        "    t_span = torch.arange(seq_len, dtype=torch.float32, device=x_seq.device) * dt\n",
        "    z_hat_traj = self.integrate_latent_ode(z0, t_span)\n",
        "    z_hat_seq = z_hat_traj.transpose(0, 1)\n",
        "    \n",
        "    x_tilde = self.decode(z_flat).reshape(batch_size, seq_len, obs_size)\n",
        "    \n",
        "    z_hat_flat = z_hat_seq.reshape(batch_size * seq_len, self.target_size)\n",
        "    x_hat_flat = self.decode(z_hat_flat)\n",
        "    x_hat_seq = x_hat_flat.reshape(batch_size, seq_len, obs_size)\n",
        "    \n",
        "    alignment_loss = torch.norm(\n",
        "        z_hat_seq[:, 1:, :] - z_seq[:, 1:, :], \n",
        "        dim=-1\n",
        "    ).pow(2).sum(dim=1).mean()\n",
        "    \n",
        "    reconst_loss = torch.norm(\n",
        "        x_seq - x_tilde,\n",
        "        dim=-1\n",
        "    ).pow(2).sum(dim=1).mean()\n",
        "    \n",
        "    prediction_loss = torch.norm(\n",
        "        x_seq[:, 1:, :] - x_hat_seq[:, 1:, :],\n",
        "        dim=-1\n",
        "    ).pow(2).sum(dim=1).mean()\n",
        "    \n",
        "    sparsity_loss = torch.norm(z_seq, p=1, dim=-1).mean()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        kmat = self.kmatrix()\n",
        "        kmat_device = kmat.device\n",
        "        if kmat_device.type == 'mps':\n",
        "            kmat_cpu = kmat.cpu()\n",
        "            eigvals = torch.linalg.eigvals(kmat_cpu)\n",
        "        else:\n",
        "            eigvals = torch.linalg.eigvals(kmat)\n",
        "        max_eigenvalue = torch.max(eigvals.real)\n",
        "        \n",
        "        num_nonzero_codes = (z_seq != 0).float().sum(dim=-1).mean()\n",
        "        sparsity_ratio = 1.0 - num_nonzero_codes / self.target_size\n",
        "    \n",
        "    total_loss = (\n",
        "        self.cfg.MODEL.RES_COEFF * alignment_loss +\n",
        "        self.cfg.MODEL.RECONST_COEFF * reconst_loss +\n",
        "        self.cfg.MODEL.PRED_COEFF * prediction_loss +\n",
        "        self.cfg.MODEL.SPARSITY_COEFF * sparsity_loss\n",
        "    )\n",
        "    \n",
        "    metrics = {\n",
        "        'loss': total_loss.item(),\n",
        "        'alignment_loss': alignment_loss.item(),\n",
        "        'reconst_loss': reconst_loss.item(),\n",
        "        'prediction_loss': prediction_loss.item(),\n",
        "        'sparsity_loss': sparsity_loss.item(),\n",
        "        'A_max_eigenvalue': max_eigenvalue.item(),\n",
        "        'sparsity_ratio': sparsity_ratio.item(),\n",
        "    }\n",
        "    \n",
        "    return total_loss, metrics\n",
        "\n",
        "\n",
        "# Attach loss methods to KoopmanMachine\n",
        "KoopmanMachine.loss = _koopman_loss\n",
        "KoopmanMachine.loss_sequence = _koopman_loss_sequence\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Concrete Model Implementations\n",
        "\n",
        "class GenericKM(KoopmanMachine):\n",
        "    \"\"\"Generic Koopman Machine with MLP encoder and decoder.\"\"\"\n",
        "    \n",
        "    def __init__(self, cfg: Config, observation_size: int):\n",
        "        super().__init__(cfg, observation_size)\n",
        "        \n",
        "        self.encoder = MLPCoder(\n",
        "            input_size=observation_size,\n",
        "            target_size=cfg.MODEL.TARGET_SIZE,\n",
        "            hidden_layers=cfg.MODEL.ENCODER.LAYERS,\n",
        "            use_bias=cfg.MODEL.ENCODER.USE_BIAS,\n",
        "            last_relu=cfg.MODEL.ENCODER.LAST_RELU,\n",
        "            activation=cfg.MODEL.ENCODER.ACTIVATION,\n",
        "        )\n",
        "        \n",
        "        self.decoder = MLPCoder(\n",
        "            input_size=cfg.MODEL.TARGET_SIZE,\n",
        "            target_size=observation_size,\n",
        "            hidden_layers=cfg.MODEL.DECODER.LAYERS,\n",
        "            use_bias=cfg.MODEL.DECODER.USE_BIAS,\n",
        "            last_relu=False,\n",
        "            activation=cfg.MODEL.DECODER.ACTIVATION,\n",
        "        )\n",
        "        \n",
        "        self.kmat = nn.Parameter(torch.eye(cfg.MODEL.TARGET_SIZE))\n",
        "        self.norm_fn_name = cfg.MODEL.NORM_FN\n",
        "    \n",
        "    def _norm_fn(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        if self.norm_fn_name == 'id':\n",
        "            return x\n",
        "        elif self.norm_fn_name == 'ball':\n",
        "            return x / torch.norm(x, dim=-1, keepdim=True)\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown norm function '{self.norm_fn_name}'\")\n",
        "    \n",
        "    def encode(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        y = self.encoder(x)\n",
        "        return self._norm_fn(y)\n",
        "    \n",
        "    def decode(self, y: torch.Tensor) -> torch.Tensor:\n",
        "        return self.decoder(y)\n",
        "    \n",
        "    def kmatrix(self) -> torch.Tensor:\n",
        "        return self.kmat\n",
        "    \n",
        "    def step_latent(self, y: torch.Tensor) -> torch.Tensor:\n",
        "        ny = y @ self.kmatrix()\n",
        "        return self._norm_fn(ny)\n",
        "\n",
        "\n",
        "class LISTAKM(KoopmanMachine):\n",
        "    \"\"\"Koopman Machine with LISTA sparse encoder.\"\"\"\n",
        "    \n",
        "    def __init__(self, cfg: Config, observation_size: int):\n",
        "        super().__init__(cfg, observation_size)\n",
        "        \n",
        "        Wd_init = torch.randn(observation_size, cfg.MODEL.TARGET_SIZE) * 0.01\n",
        "        self.register_buffer('dict_init', Wd_init.clone())\n",
        "        self.dict = nn.Parameter(Wd_init.T)\n",
        "        \n",
        "        self.lista = LISTA(cfg, observation_size, Wd_init)\n",
        "        self.kmat = nn.Parameter(torch.eye(cfg.MODEL.TARGET_SIZE))\n",
        "    \n",
        "    def encode(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.lista(x)\n",
        "    \n",
        "    def decode(self, y: torch.Tensor) -> torch.Tensor:\n",
        "        wd = self.dict / torch.norm(self.dict, dim=1, keepdim=True).clamp(min=1e-4)\n",
        "        return y @ wd\n",
        "    \n",
        "    def kmatrix(self) -> torch.Tensor:\n",
        "        return self.kmat\n",
        "    \n",
        "    def sparsity_loss(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        z = self.encode(x)\n",
        "        return self.cfg.MODEL.ENCODER.LISTA.ALPHA * torch.norm(z, p=1, dim=-1).mean()\n",
        "\n",
        "\n",
        "# Model Registry and Factory\n",
        "\n",
        "_MODEL_REGISTRY = {\n",
        "    \"GenericKM\": GenericKM,\n",
        "    \"SparseKM\": GenericKM,\n",
        "    \"LISTAKM\": LISTAKM,\n",
        "}\n",
        "\n",
        "\n",
        "def make_model(cfg: Config, observation_size: int) -> KoopmanMachine:\n",
        "    \"\"\"Factory function to create model from configuration.\"\"\"\n",
        "    model_name = cfg.MODEL.MODEL_NAME\n",
        "    if model_name not in _MODEL_REGISTRY:\n",
        "        raise ValueError(\n",
        "            f\"Unknown model '{model_name}'. \"\n",
        "            f\"Available: {list(_MODEL_REGISTRY.keys())}\"\n",
        "        )\n",
        "    return _MODEL_REGISTRY[model_name](cfg, observation_size)\n",
        "\n",
        "\n",
        "print(\"✓ Koopman autoencoder models loaded.\")\n",
        "print(f\"  Available models: {list(_MODEL_REGISTRY.keys())}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 5. Training Pipeline\n",
        "\n",
        "This section implements the training loop for Koopman autoencoders.\n",
        "\n",
        "### Training Modes\n",
        "\n",
        "1. **Pairwise (single-step) training**: Uses pairs (x, x') of consecutive states\n",
        "2. **Sequence training**: Uses sequences of states with ODE integration\n",
        "\n",
        "### Optimizer\n",
        "\n",
        "Uses AdamW with separate learning rates for:\n",
        "- Encoder/Decoder parameters: `cfg.TRAIN.LR`\n",
        "- Koopman matrix: `cfg.TRAIN.K_MATRIX_LR` (typically smaller)\n",
        "\n",
        "### Logging\n",
        "\n",
        "Metrics are logged to JSONL files for later analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# TRAINING PIPELINE (train.py)\n",
        "# =============================================================================\n",
        "\n",
        "class MetricsLogger:\n",
        "    \"\"\"Simple file-based metrics logger.\"\"\"\n",
        "    \n",
        "    def __init__(self, log_dir: Path, flush_interval: int = 100):\n",
        "        self.log_dir = log_dir\n",
        "        self.metrics_file = log_dir / 'metrics_history.jsonl'\n",
        "        self.metrics_history: List[Dict] = []\n",
        "        self.buffer: List[str] = []\n",
        "        self.flush_interval = flush_interval\n",
        "        self.step_count = 0\n",
        "    \n",
        "    def log_scalar(self, name: str, value: float, step: int):\n",
        "        entry = {'step': step, 'name': name, 'value': value}\n",
        "        self.buffer.append(json.dumps(entry) + '\\n')\n",
        "        self.metrics_history.append(entry)\n",
        "        self.step_count += 1\n",
        "        if len(self.buffer) >= self.flush_interval:\n",
        "            self.flush()\n",
        "    \n",
        "    def flush(self):\n",
        "        if self.buffer:\n",
        "            with open(self.metrics_file, 'a') as f:\n",
        "                f.writelines(self.buffer)\n",
        "            self.buffer.clear()\n",
        "    \n",
        "    def log_dict(self, metrics: Dict[str, float], step: int, prefix: str = ''):\n",
        "        for key, value in metrics.items():\n",
        "            name = f\"{prefix}/{key}\" if prefix else key\n",
        "            self.log_scalar(name, value, step)\n",
        "    \n",
        "    def close(self):\n",
        "        self.flush()\n",
        "        summary_file = self.log_dir / 'metrics_summary.json'\n",
        "        summary = {}\n",
        "        metrics_by_name = {}\n",
        "        for entry in self.metrics_history:\n",
        "            name = entry['name']\n",
        "            if name not in metrics_by_name:\n",
        "                metrics_by_name[name] = []\n",
        "            metrics_by_name[name].append(entry['value'])\n",
        "        \n",
        "        for name, values in metrics_by_name.items():\n",
        "            summary[name] = {\n",
        "                'final': values[-1] if values else None,\n",
        "                'min': min(values) if values else None,\n",
        "                'max': max(values) if values else None,\n",
        "                'mean': sum(values) / len(values) if values else None,\n",
        "            }\n",
        "        \n",
        "        with open(summary_file, 'w') as f:\n",
        "            json.dump(summary, f, indent=2)\n",
        "\n",
        "\n",
        "def train_step(\n",
        "    model: nn.Module,\n",
        "    optimizer: torch.optim.Optimizer,\n",
        "    x: torch.Tensor,\n",
        "    nx: torch.Tensor,\n",
        "    cfg: Config,\n",
        "    dt: float,\n",
        ") -> Dict[str, float]:\n",
        "    \"\"\"Perform one training step.\"\"\"\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    if cfg.TRAIN.USE_SEQUENCE_LOSS:\n",
        "        loss, metrics = model.loss_sequence(x, dt)\n",
        "    else:\n",
        "        loss, metrics = model.loss(x, nx)\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return metrics\n",
        "\n",
        "\n",
        "def build_optimizer(model: nn.Module, cfg: Config) -> torch.optim.Optimizer:\n",
        "    \"\"\"Create optimizer with separate learning rate for Koopman matrix.\"\"\"\n",
        "    kmat_params = []\n",
        "    other_params = []\n",
        "    for name, param in model.named_parameters():\n",
        "        if not param.requires_grad:\n",
        "            continue\n",
        "        if 'kmat' in name:\n",
        "            kmat_params.append(param)\n",
        "        else:\n",
        "            other_params.append(param)\n",
        "\n",
        "    param_groups = []\n",
        "    if other_params:\n",
        "        param_groups.append({\n",
        "            'params': other_params,\n",
        "            'lr': cfg.TRAIN.LR,\n",
        "            'weight_decay': cfg.TRAIN.WEIGHT_DECAY,\n",
        "        })\n",
        "    if kmat_params:\n",
        "        param_groups.append({\n",
        "            'params': kmat_params,\n",
        "            'lr': cfg.TRAIN.K_MATRIX_LR,\n",
        "            'weight_decay': 0.0,\n",
        "        })\n",
        "\n",
        "    return torch.optim.AdamW(param_groups)\n",
        "\n",
        "\n",
        "def get_dt_from_config(cfg: Config) -> float:\n",
        "    \"\"\"Extract dt from environment config.\"\"\"\n",
        "    env_name = cfg.ENV.ENV_NAME.lower()\n",
        "    if env_name == 'duffing':\n",
        "        return cfg.ENV.DUFFING.DT\n",
        "    elif env_name == 'pendulum':\n",
        "        return cfg.ENV.PENDULUM.DT\n",
        "    elif env_name == 'lotka_volterra':\n",
        "        return cfg.ENV.LOTKA_VOLTERRA.DT\n",
        "    elif env_name == 'lorenz63':\n",
        "        return cfg.ENV.LORENZ63.DT\n",
        "    elif env_name == 'parabolic':\n",
        "        return cfg.ENV.PARABOLIC.DT\n",
        "    elif env_name == 'lyapunov':\n",
        "        return cfg.ENV.LYAPUNOV.DT\n",
        "    else:\n",
        "        return 0.01\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Main training function\n",
        "\n",
        "def train(\n",
        "    cfg: Config,\n",
        "    log_dir: Optional[str] = None,\n",
        "    checkpoint_path: Optional[str] = None,\n",
        "    device: str = 'cuda',\n",
        "    run_evaluation: bool = True,\n",
        ") -> nn.Module:\n",
        "    \"\"\"Main training function.\n",
        "    \n",
        "    Args:\n",
        "        cfg: Configuration object\n",
        "        log_dir: Directory for logs and checkpoints\n",
        "        checkpoint_path: Path to checkpoint to resume from\n",
        "        device: Device to train on ('cpu', 'cuda', 'mps')\n",
        "        run_evaluation: Whether to run evaluation after training\n",
        "        \n",
        "    Returns:\n",
        "        Trained model\n",
        "    \"\"\"\n",
        "    print(\"Initializing training...\")\n",
        "    \n",
        "    # Setup logging directory\n",
        "    if log_dir is None:\n",
        "        log_dir = './runs/kae'\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "    run_dir = Path(log_dir) / timestamp\n",
        "    run_dir.mkdir(parents=True, exist_ok=True)\n",
        "    cfg.to_json(str(run_dir / 'config.json'))\n",
        "    \n",
        "    logger = MetricsLogger(run_dir)\n",
        "    \n",
        "    # Set random seed\n",
        "    torch.manual_seed(cfg.SEED)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(cfg.SEED)\n",
        "    \n",
        "    # Create environment\n",
        "    print(\"Creating environment...\")\n",
        "    env = make_env(cfg)\n",
        "    env = VectorWrapper(env, cfg.TRAIN.BATCH_SIZE)\n",
        "    \n",
        "    # Get dt from config\n",
        "    dt = get_dt_from_config(cfg)\n",
        "    \n",
        "    # Create model\n",
        "    print(\"Creating model...\")\n",
        "    model = make_model(cfg, env.observation_size)\n",
        "    model = model.to(device)\n",
        "    model.dt = dt\n",
        "    \n",
        "    # Build optimizer\n",
        "    print(\"Building optimizer...\")\n",
        "    optimizer = build_optimizer(model, cfg)\n",
        "    \n",
        "    start_step = 0\n",
        "    if checkpoint_path is not None:\n",
        "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        start_step = checkpoint.get('step', 0)\n",
        "        print(f\"Resumed from checkpoint at step {start_step}\")\n",
        "    \n",
        "    # Pre-generate random number generators\n",
        "    num_batches = cfg.TRAIN.DATA_SIZE // cfg.TRAIN.BATCH_SIZE\n",
        "    rngs = [torch.Generator().manual_seed(cfg.SEED + i * cfg.TRAIN.BATCH_SIZE) for i in range(num_batches)]\n",
        "    \n",
        "    print(f\"Training {cfg.MODEL.MODEL_NAME} on {cfg.ENV.ENV_NAME}\")\n",
        "    print(f\"Device: {device}\")\n",
        "    print(f\"Observation size: {env.observation_size}\")\n",
        "    print(f\"Target size: {cfg.MODEL.TARGET_SIZE}\")\n",
        "    print(f\"Batch size: {cfg.TRAIN.BATCH_SIZE}\")\n",
        "    print(f\"Total steps: {cfg.TRAIN.NUM_STEPS}\")\n",
        "    print(f\"Log directory: {run_dir}\")\n",
        "    print(\"-\" * 80)\n",
        "    \n",
        "    best_eval_final_error = float('inf')\n",
        "    \n",
        "    for step in range(start_step, cfg.TRAIN.NUM_STEPS):\n",
        "        rng = rngs[step % num_batches]\n",
        "        \n",
        "        if cfg.TRAIN.USE_SEQUENCE_LOSS:\n",
        "            x_seq = env.generate_sequence_batch(rng, window_length=cfg.TRAIN.SEQUENCE_LENGTH)\n",
        "            x_seq = x_seq.to(device)\n",
        "            nx = None\n",
        "            metrics = train_step(model, optimizer, x_seq, nx, cfg, dt)\n",
        "        else:\n",
        "            x = env.reset(rng)\n",
        "            nx = env.step(x)\n",
        "            x = x.to(device)\n",
        "            nx = nx.to(device)\n",
        "            metrics = train_step(model, optimizer, x, nx, cfg, dt)\n",
        "        \n",
        "        logger.log_dict(metrics, step, prefix='train')\n",
        "        \n",
        "        if step % 100 == 0:\n",
        "            if cfg.TRAIN.USE_SEQUENCE_LOSS:\n",
        "                print(f\"Step {step}/{cfg.TRAIN.NUM_STEPS} | \"\n",
        "                      f\"Loss: {metrics['loss']:.4f} | \"\n",
        "                      f\"Align: {metrics['alignment_loss']:.4f} | \"\n",
        "                      f\"Recon: {metrics['reconst_loss']:.4f} | \"\n",
        "                      f\"Sparsity: {metrics['sparsity_ratio']:.3f}\")\n",
        "            else:\n",
        "                print(f\"Step {step}/{cfg.TRAIN.NUM_STEPS} | \"\n",
        "                      f\"Loss: {metrics['loss']:.4f} | \"\n",
        "                      f\"Res: {metrics['residual_loss']:.4f} | \"\n",
        "                      f\"Recon: {metrics['reconst_loss']:.4f} | \"\n",
        "                      f\"Sparsity: {metrics['sparsity_ratio']:.3f}\")\n",
        "        \n",
        "        # Periodic checkpoint saving\n",
        "        if step % 500 == 0 or step == cfg.TRAIN.NUM_STEPS - 1:\n",
        "            if cfg.TRAIN.USE_SEQUENCE_LOSS:\n",
        "                eval_x = x_seq[:4, 0, :]\n",
        "            else:\n",
        "                eval_x = x[:4]\n",
        "            \n",
        "            eval_results = quick_evaluate(model, eval_x, lambda s: env.step(s), num_steps=200)\n",
        "            logger.log_scalar('eval/mean_error', eval_results['mean_error'], step)\n",
        "            logger.log_scalar('eval/final_error', eval_results['final_error'], step)\n",
        "            \n",
        "            print(f\"  Eval | Mean error: {eval_results['mean_error']:.4f} | \"\n",
        "                  f\"Final error: {eval_results['final_error']:.4f}\")\n",
        "            \n",
        "            checkpoint_dict = {\n",
        "                'step': step,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'config': cfg.to_dict(),\n",
        "                'metrics': metrics,\n",
        "            }\n",
        "            \n",
        "            torch.save(checkpoint_dict, run_dir / 'last.pt')\n",
        "            \n",
        "            if eval_results['final_error'] < best_eval_final_error:\n",
        "                best_eval_final_error = eval_results['final_error']\n",
        "                torch.save(checkpoint_dict, run_dir / 'checkpoint.pt')\n",
        "                print(f\"  Saved best checkpoint (final eval error: {best_eval_final_error:.4f})\")\n",
        "    \n",
        "    # Save final metrics\n",
        "    with open(run_dir / 'final_metrics.json', 'w') as f:\n",
        "        json.dump(metrics, f, indent=2)\n",
        "    \n",
        "    logger.close()\n",
        "    \n",
        "    print(\"-\" * 80)\n",
        "    print(f\"Training complete! Checkpoints saved to {run_dir}\")\n",
        "    \n",
        "    # Run evaluation if requested\n",
        "    if run_evaluation:\n",
        "        print(\"Running evaluation...\")\n",
        "        eval_results = evaluate_model(\n",
        "            model=model,\n",
        "            cfg=cfg,\n",
        "            device=device,\n",
        "            output_dir=run_dir / 'evaluation',\n",
        "        )\n",
        "        print(\"Evaluation complete!\")\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "def quick_evaluate(\n",
        "    model: nn.Module,\n",
        "    x: torch.Tensor,\n",
        "    env_step_fn,\n",
        "    num_steps: int = 50,\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"Quick evaluation helper used during training.\"\"\"\n",
        "    model.eval()\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    with torch.no_grad():\n",
        "        true_traj = generate_trajectory(env_step_fn, x.cpu(), length=num_steps)\n",
        "        pred_traj = rollout_every_step_reencode(model, x.to(device), num_steps)\n",
        "\n",
        "        pred_traj_cpu = pred_traj.cpu()\n",
        "        step_error = torch.norm(pred_traj_cpu - true_traj, dim=-1).mean(dim=1)\n",
        "\n",
        "        return {\n",
        "            \"true_trajectory\": true_traj,\n",
        "            \"pred_trajectory\": pred_traj_cpu,\n",
        "            \"pred_error\": step_error,\n",
        "            \"mean_error\": step_error.mean().item(),\n",
        "            \"final_error\": step_error[-1].item(),\n",
        "        }\n",
        "\n",
        "\n",
        "print(\"✓ Training pipeline loaded.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 6. Evaluation Module\n",
        "\n",
        "This section implements comprehensive evaluation for trained Koopman models.\n",
        "\n",
        "### Rollout Strategies\n",
        "\n",
        "1. **No reencoding** (`no_reencode`): Evolves entirely in latent space\n",
        "2. **Every-step reencoding** (`every_step`): Reencodes at each step\n",
        "3. **Periodic reencoding** (`periodic_k`): Reencodes every k steps\n",
        "\n",
        "### Metrics\n",
        "\n",
        "- **Horizon-wise MSE**: Mean squared error at specific prediction horizons\n",
        "- **Cumulative MSE curve**: Time-averaged MSE vs. prediction horizon\n",
        "- **Per-step L2 error**: Mean L2 error at each prediction step\n",
        "\n",
        "### Visualizations\n",
        "\n",
        "- Phase portraits comparing true vs. predicted trajectories\n",
        "- MSE vs. horizon curves\n",
        "- Error curves for each rollout mode\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# EVALUATION MODULE (evaluation.py)\n",
        "# =============================================================================\n",
        "\n",
        "# Rollout generators\n",
        "\n",
        "@torch.no_grad()\n",
        "def rollout_no_reencode(model: KoopmanMachine, x0: torch.Tensor, horizon: int) -> torch.Tensor:\n",
        "    \"\"\"Roll out the Koopman dynamics without reencoding.\"\"\"\n",
        "    model.eval()\n",
        "    device = next(model.parameters()).device\n",
        "    x0 = x0.to(device)\n",
        "\n",
        "    latent = model.encode(x0)\n",
        "    predictions: List[torch.Tensor] = []\n",
        "\n",
        "    for _ in range(horizon):\n",
        "        latent = model.step_latent(latent)\n",
        "        x_pred = model.decode(latent)\n",
        "        predictions.append(x_pred)\n",
        "\n",
        "        if not torch.isfinite(x_pred).all():\n",
        "            nan_frame = torch.full_like(x_pred, torch.nan)\n",
        "            predictions.extend([nan_frame] * (horizon - len(predictions)))\n",
        "            break\n",
        "\n",
        "    return torch.stack(predictions, dim=0)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def rollout_every_step_reencode(\n",
        "    model: KoopmanMachine,\n",
        "    x0: torch.Tensor,\n",
        "    horizon: int,\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"Roll out the Koopman dynamics with reencoding at every step.\"\"\"\n",
        "    model.eval()\n",
        "    device = next(model.parameters()).device\n",
        "    state = x0.to(device)\n",
        "    predictions: List[torch.Tensor] = []\n",
        "\n",
        "    for _ in range(horizon):\n",
        "        state = model.step_env(state)\n",
        "        predictions.append(state)\n",
        "\n",
        "        if not torch.isfinite(state).all():\n",
        "            nan_frame = torch.full_like(state, torch.nan)\n",
        "            predictions.extend([nan_frame] * (horizon - len(predictions)))\n",
        "            break\n",
        "\n",
        "    return torch.stack(predictions, dim=0)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def rollout_periodic_reencode(\n",
        "    model: KoopmanMachine,\n",
        "    x0: torch.Tensor,\n",
        "    horizon: int,\n",
        "    period: int,\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"Roll out the Koopman dynamics with periodic reencoding every *period* steps.\"\"\"\n",
        "    if period <= 0:\n",
        "        raise ValueError(\"period must be a positive integer\")\n",
        "\n",
        "    model.eval()\n",
        "    device = next(model.parameters()).device\n",
        "    x0 = x0.to(device)\n",
        "\n",
        "    latent = model.encode(x0)\n",
        "    predictions: List[torch.Tensor] = []\n",
        "\n",
        "    for step in range(horizon):\n",
        "        latent = model.step_latent(latent)\n",
        "        x_pred = model.decode(latent)\n",
        "        predictions.append(x_pred)\n",
        "\n",
        "        if not torch.isfinite(x_pred).all():\n",
        "            nan_frame = torch.full_like(x_pred, torch.nan)\n",
        "            predictions.extend([nan_frame] * (horizon - len(predictions)))\n",
        "            break\n",
        "\n",
        "        if (step + 1) % period == 0:\n",
        "            latent = model.encode(x_pred)\n",
        "\n",
        "    return torch.stack(predictions, dim=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Metric computation helpers\n",
        "\n",
        "def _compute_horizon_mse(\n",
        "    squared_errors: torch.Tensor,\n",
        "    horizon: int,\n",
        ") -> Tuple[float, float, List[float], int]:\n",
        "    \"\"\"Compute mean +/- std MSE for a specific horizon.\"\"\"\n",
        "    horizon = min(horizon, squared_errors.size(0))\n",
        "    horizon_errors = squared_errors[:horizon]\n",
        "    per_ic = torch.nanmean(horizon_errors, dim=0)\n",
        "    valid_mask = torch.isfinite(per_ic)\n",
        "\n",
        "    if valid_mask.sum() == 0:\n",
        "        return float(\"nan\"), float(\"nan\"), [], 0\n",
        "\n",
        "    valid_errors = per_ic[valid_mask]\n",
        "    mean = valid_errors.mean().item()\n",
        "    std = valid_errors.std(unbiased=False).item() if valid_errors.numel() > 1 else 0.0\n",
        "    return mean, std, valid_errors.tolist(), int(valid_mask.sum().item())\n",
        "\n",
        "\n",
        "def _cumulative_mse_curve(squared_errors: torch.Tensor) -> List[float]:\n",
        "    \"\"\"Compute cumulative MSE curve averaged across initial conditions.\"\"\"\n",
        "    time_steps = squared_errors.size(0)\n",
        "    steps = torch.arange(1, time_steps + 1, dtype=torch.float32, device=squared_errors.device)\n",
        "    cumulative = torch.cumsum(squared_errors, dim=0)\n",
        "    with torch.no_grad():\n",
        "        curve = torch.nanmean(cumulative / steps.view(-1, 1), dim=1)\n",
        "    return curve.cpu().tolist()\n",
        "\n",
        "\n",
        "# Evaluation settings\n",
        "\n",
        "@dataclass\n",
        "class EvaluationSettings:\n",
        "    \"\"\"Container for evaluation hyper-parameters.\"\"\"\n",
        "    systems: Sequence[str] = (\"duffing\", \"lyapunov\")\n",
        "    horizons: Sequence[int] = (100, 1000)\n",
        "    periodic_reencode_periods: Sequence[int] = (10, 25, 50, 100)\n",
        "    batch_size: int = 100\n",
        "    phase_portrait_samples: int = 20\n",
        "    phase_portrait_length: int = 200\n",
        "    phase_portrait_reencode_periods: Sequence[int] = (0, 1, 10, 25, 50)\n",
        "    phase_portrait_batch_size: int = 256\n",
        "    seed_offset: int = 12345\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plotting utilities for evaluation\n",
        "\n",
        "def _save_mse_curve_plot(curves: Dict[str, List[float]], path: Path, highlight_horizons: Sequence[int]) -> None:\n",
        "    \"\"\"Save MSE vs horizon curves for each rollout mode.\"\"\"\n",
        "    path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(7, 5))\n",
        "    for mode, curve in curves.items():\n",
        "        xs = np.arange(1, len(curve) + 1)\n",
        "        ax.plot(xs, curve, linewidth=2, label=mode)\n",
        "\n",
        "    for horizon in highlight_horizons:\n",
        "        ax.axvline(horizon, color=\"gray\", linestyle=\"--\", linewidth=1.0, alpha=0.5)\n",
        "\n",
        "    ax.set_xlabel(\"Prediction horizon\")\n",
        "    ax.set_ylabel(\"Mean MSE\")\n",
        "    ax.set_title(\"MSE vs horizon\")\n",
        "    ax.grid(True, linestyle=\":\", alpha=0.4)\n",
        "    ax.legend()\n",
        "    fig.tight_layout()\n",
        "    fig.savefig(path, dpi=200)\n",
        "    plt.close(fig)\n",
        "\n",
        "\n",
        "def _save_error_curve_combined(\n",
        "    errors_by_mode: Dict[str, torch.Tensor],\n",
        "    path: Path,\n",
        "    highlight_steps: Optional[Sequence[int]] = None,\n",
        ") -> None:\n",
        "    \"\"\"Save combined per-step mean error curves for all rollout modes.\"\"\"\n",
        "    path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(7, 5))\n",
        "    for mode, errors in errors_by_mode.items():\n",
        "        error_np = errors.cpu().numpy()\n",
        "        steps = np.arange(1, error_np.shape[0] + 1)\n",
        "        ax.plot(steps, error_np, linewidth=2, label=mode)\n",
        "\n",
        "    if highlight_steps is not None:\n",
        "        for step in highlight_steps:\n",
        "            if step <= 0:\n",
        "                continue\n",
        "            ax.axvline(step, color=\"gray\", linestyle=\"--\", linewidth=1.0, alpha=0.5)\n",
        "\n",
        "    ax.set_xlabel(\"Prediction step\")\n",
        "    ax.set_ylabel(\"Mean L2 error\")\n",
        "    ax.set_title(\"Per-step prediction error (all modes)\")\n",
        "    ax.grid(True, linestyle=\":\", alpha=0.4)\n",
        "    ax.legend()\n",
        "    fig.tight_layout()\n",
        "    fig.savefig(path, dpi=300)\n",
        "    plt.close(fig)\n",
        "\n",
        "\n",
        "def _make_km_env_n_step(\n",
        "    model: KoopmanMachine,\n",
        "    x: torch.Tensor,\n",
        "    length: int,\n",
        "    reencode_at_every: int,\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"Generate rollout with configurable reencoding period.\"\"\"\n",
        "    device = next(model.parameters()).device\n",
        "    x = x.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        if reencode_at_every == 1:\n",
        "            traj = []\n",
        "            state = x\n",
        "            for _ in range(length):\n",
        "                state = model.step_env(state)\n",
        "                traj.append(state.detach().cpu())\n",
        "            return torch.stack(traj, dim=0)\n",
        "        elif reencode_at_every == 0:\n",
        "            traj = []\n",
        "            latent = model.encode(x)\n",
        "            for _ in range(length):\n",
        "                latent = model.step_latent(latent)\n",
        "                decoded = model.decode(latent)\n",
        "                traj.append(decoded.detach().cpu())\n",
        "            return torch.stack(traj, dim=0)\n",
        "        else:\n",
        "            assert length % reencode_at_every == 0, (\n",
        "                \"length must be divisible by reencode_at_every when > 1\"\n",
        "            )\n",
        "            state = x\n",
        "            num_slices = length // reencode_at_every\n",
        "            chunks: List[torch.Tensor] = []\n",
        "            for _ in range(num_slices):\n",
        "                latent = model.encode(state)\n",
        "                chunk_states = []\n",
        "                z = latent\n",
        "                for _ in range(reencode_at_every):\n",
        "                    z = model.step_latent(z)\n",
        "                    decoded = model.decode(z)\n",
        "                    chunk_states.append(decoded.detach().cpu())\n",
        "                chunk = torch.stack(chunk_states, dim=0)\n",
        "                chunks.append(chunk)\n",
        "                state = chunk[-1].to(device)\n",
        "            return torch.cat(chunks, dim=0)\n",
        "\n",
        "\n",
        "def _save_jax_style_phase_portraits(\n",
        "    model: KoopmanMachine,\n",
        "    base_env,\n",
        "    cfg: Config,\n",
        "    settings: EvaluationSettings,\n",
        "    path: Path,\n",
        ") -> None:\n",
        "    \"\"\"Generate phase portrait grid for different reencoding periods.\"\"\"\n",
        "    if base_env.observation_size < 2:\n",
        "        return\n",
        "\n",
        "    batch_size = settings.phase_portrait_batch_size\n",
        "    length = settings.phase_portrait_length\n",
        "    reencode_periods = settings.phase_portrait_reencode_periods\n",
        "\n",
        "    vec_env = VectorWrapper(base_env, batch_size)\n",
        "    rng = torch.Generator().manual_seed(cfg.SEED + settings.seed_offset + 999)\n",
        "    init_states = vec_env.reset(rng)\n",
        "\n",
        "    trajectories = {}\n",
        "    for period in reencode_periods:\n",
        "        traj = _make_km_env_n_step(model, init_states, length, period)\n",
        "        trajectories[period] = traj\n",
        "\n",
        "    num_modes = len(reencode_periods)\n",
        "    fig, axes = plt.subplots(1, num_modes, figsize=(6 * num_modes, 5), squeeze=False)\n",
        "\n",
        "    for ax, period in zip(axes[0], reencode_periods):\n",
        "        traj = trajectories[period]\n",
        "        ax.plot(traj[:, :, 0], traj[:, :, 1])\n",
        "        if period == 0:\n",
        "            title = \"reencode [x]\"\n",
        "        elif period == 1:\n",
        "            title = \"reencode @ 1\"\n",
        "        else:\n",
        "            title = f\"reencode @ {period}\"\n",
        "        ax.set_title(title)\n",
        "        ax.set_xlabel(\"x1\")\n",
        "        ax.set_ylabel(\"x2\")\n",
        "        ax.set_aspect(\"equal\", adjustable=\"box\")\n",
        "        ax.grid(True, linestyle=\":\", alpha=0.4)\n",
        "\n",
        "    fig.tight_layout()\n",
        "    path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    fig.savefig(path, dpi=300)\n",
        "    plt.close(fig)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Main evaluation function\n",
        "\n",
        "def evaluate_model(\n",
        "    model: KoopmanMachine,\n",
        "    cfg: Config,\n",
        "    device: str = \"cuda\",\n",
        "    settings: Optional[EvaluationSettings] = None,\n",
        "    output_dir: Optional[Path] = None,\n",
        ") -> Dict[str, Dict]:\n",
        "    \"\"\"Evaluate a trained Koopman model using the standardized protocol.\"\"\"\n",
        "\n",
        "    if settings is None:\n",
        "        settings = EvaluationSettings()\n",
        "        # Only evaluate on the training system by default\n",
        "        settings.systems = [cfg.ENV.ENV_NAME]\n",
        "\n",
        "    print(f\"[evaluate_model] Starting evaluation for systems={tuple(settings.systems)}\")\n",
        "\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    max_horizon = max(settings.horizons)\n",
        "    results: Dict[str, Dict] = {}\n",
        "\n",
        "    for system in settings.systems:\n",
        "        print(f\"[evaluate_model] -> System '{system}': preparing environment...\")\n",
        "        eval_cfg = Config.from_dict(cfg.to_dict())\n",
        "        eval_cfg.ENV.ENV_NAME = system\n",
        "\n",
        "        base_env = make_env(eval_cfg)\n",
        "        if base_env.observation_size != model.observation_size:\n",
        "            print(f\"[evaluate_model] -> System '{system}': skipped (observation size mismatch)\")\n",
        "            continue\n",
        "\n",
        "        vec_env = VectorWrapper(base_env, settings.batch_size)\n",
        "        rng = torch.Generator().manual_seed(cfg.SEED + settings.seed_offset)\n",
        "        init_states = vec_env.reset(rng)\n",
        "\n",
        "        # Generate ground truth trajectories\n",
        "        print(f\"[evaluate_model] -> System '{system}': generating ground-truth trajectory\")\n",
        "        true_future = generate_trajectory(vec_env.step, init_states, length=max_horizon)\n",
        "\n",
        "        init_states_device = init_states.to(device)\n",
        "\n",
        "        predictions: Dict[str, torch.Tensor] = {}\n",
        "        print(f\"[evaluate_model] -> System '{system}': running rollout modes...\")\n",
        "        predictions[\"no_reencode\"] = rollout_no_reencode(model, init_states_device, max_horizon)\n",
        "        predictions[\"every_step\"] = rollout_every_step_reencode(model, init_states_device, max_horizon)\n",
        "\n",
        "        for period in settings.periodic_reencode_periods:\n",
        "            mode_name = f\"periodic_{period}\"\n",
        "            predictions[mode_name] = rollout_periodic_reencode(\n",
        "                model, init_states_device, max_horizon, period=period\n",
        "            )\n",
        "\n",
        "        mode_metrics: Dict[str, Dict] = {}\n",
        "        periodic_summary: Dict[str, Dict[str, float]] = {str(h): {} for h in settings.horizons}\n",
        "        per_step_errors: Dict[str, torch.Tensor] = {}\n",
        "\n",
        "        true_future_cpu = true_future.float()\n",
        "\n",
        "        print(f\"[evaluate_model] -> System '{system}': computing metrics...\")\n",
        "        for mode_name, pred in predictions.items():\n",
        "            pred_cpu = pred.detach().cpu().float()\n",
        "\n",
        "            per_step_error = torch.norm(pred_cpu - true_future_cpu, dim=-1).mean(dim=1)\n",
        "            per_step_errors[mode_name] = per_step_error\n",
        "\n",
        "            squared_diff = torch.sum((pred_cpu - true_future_cpu) ** 2, dim=-1)\n",
        "            squared_diff = torch.where(torch.isfinite(squared_diff), squared_diff, torch.nan)\n",
        "\n",
        "            horizons_metrics = {}\n",
        "            for horizon in settings.horizons:\n",
        "                if system == \"parabolic\" and horizon > 100:\n",
        "                    continue\n",
        "\n",
        "                mean, std, per_ic, num_valid = _compute_horizon_mse(squared_diff, horizon)\n",
        "                horizons_metrics[str(horizon)] = {\n",
        "                    \"mean\": mean,\n",
        "                    \"std\": std,\n",
        "                    \"num_valid\": num_valid,\n",
        "                }\n",
        "\n",
        "                if mode_name.startswith(\"periodic_\") and num_valid > 0:\n",
        "                    periodic_summary[str(horizon)][mode_name] = mean\n",
        "\n",
        "            mode_metrics[mode_name] = {\n",
        "                \"horizons\": horizons_metrics,\n",
        "                \"mse_curve\": _cumulative_mse_curve(squared_diff),\n",
        "            }\n",
        "\n",
        "        # Determine best periodic reencoding period per horizon\n",
        "        best_periodic: Dict[str, Dict[str, float]] = {}\n",
        "        for horizon in settings.horizons:\n",
        "            horizon_key = str(horizon)\n",
        "            if system == \"parabolic\" and horizon > 100:\n",
        "                continue\n",
        "\n",
        "            candidates = periodic_summary[horizon_key]\n",
        "            if not candidates:\n",
        "                continue\n",
        "\n",
        "            best_mode = min(candidates.items(), key=lambda item: item[1])\n",
        "            best_periodic[horizon_key] = {\n",
        "                \"mode\": best_mode[0],\n",
        "                \"mean\": best_mode[1],\n",
        "            }\n",
        "\n",
        "        # Save plots\n",
        "        files: Dict[str, str] = {}\n",
        "        if output_dir is not None:\n",
        "            system_dir = output_dir / system\n",
        "            system_dir.mkdir(parents=True, exist_ok=True)\n",
        "            print(f\"[evaluate_model] -> System '{system}': saving plots to {system_dir}\")\n",
        "\n",
        "            # Phase portrait grid\n",
        "            portrait_path = system_dir / \"phase_portrait_plot_eval.png\"\n",
        "            _save_jax_style_phase_portraits(model, base_env, cfg, settings, portrait_path)\n",
        "            files[\"phase_portrait_plot_eval\"] = str(portrait_path)\n",
        "\n",
        "            # MSE curves\n",
        "            curves = {mode: data[\"mse_curve\"] for mode, data in mode_metrics.items()}\n",
        "            curve_path = system_dir / \"mse_vs_horizon.png\"\n",
        "            _save_mse_curve_plot(curves, curve_path, settings.horizons)\n",
        "            files[\"mse_curve\"] = str(curve_path)\n",
        "\n",
        "            # Combined error curve\n",
        "            combined_error_path = system_dir / \"error_curve_combined.png\"\n",
        "            _save_error_curve_combined(per_step_errors, combined_error_path, highlight_steps=settings.horizons)\n",
        "            files[\"error_curve_combined\"] = str(combined_error_path)\n",
        "\n",
        "        results[system] = {\n",
        "            \"modes\": mode_metrics,\n",
        "            \"best_periodic\": best_periodic,\n",
        "            \"files\": files,\n",
        "        }\n",
        "\n",
        "    if output_dir is not None:\n",
        "        output_dir.mkdir(parents=True, exist_ok=True)\n",
        "        metrics_path = output_dir / \"metrics.json\"\n",
        "        with metrics_path.open(\"w\") as f:\n",
        "            json.dump(results, f, indent=2)\n",
        "        results[\"metrics_file\"] = str(metrics_path)\n",
        "\n",
        "    print(\"[evaluate_model] Finished evaluation.\")\n",
        "    return results\n",
        "\n",
        "\n",
        "print(\"✓ Evaluation module loaded.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 7. Visualization Utilities\n",
        "\n",
        "Utilities for plotting training metrics from log files.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# VISUALIZATION UTILITIES (plot_training_metrics.py)\n",
        "# =============================================================================\n",
        "\n",
        "def load_metrics_history(log_dir: Path) -> Dict[str, List]:\n",
        "    \"\"\"Load metrics history from JSONL file.\"\"\"\n",
        "    metrics_file = log_dir / 'metrics_history.jsonl'\n",
        "    \n",
        "    if not metrics_file.exists():\n",
        "        raise FileNotFoundError(f\"Metrics file not found: {metrics_file}\")\n",
        "    \n",
        "    metrics_data = {}\n",
        "    \n",
        "    with open(metrics_file, 'r') as f:\n",
        "        for line in f:\n",
        "            entry = json.loads(line.strip())\n",
        "            name = entry['name']\n",
        "            step = entry['step']\n",
        "            value = entry['value']\n",
        "            \n",
        "            if name not in metrics_data:\n",
        "                metrics_data[name] = {'steps': [], 'values': []}\n",
        "            \n",
        "            metrics_data[name]['steps'].append(step)\n",
        "            metrics_data[name]['values'].append(value)\n",
        "    \n",
        "    return metrics_data\n",
        "\n",
        "\n",
        "def plot_metrics(\n",
        "    log_dir: Path,\n",
        "    metrics_to_plot: Optional[List[str]] = None,\n",
        "    save_path: Optional[Path] = None,\n",
        "):\n",
        "    \"\"\"Plot training metrics.\"\"\"\n",
        "    metrics_data = load_metrics_history(log_dir)\n",
        "    \n",
        "    # Filter metrics if specified\n",
        "    if metrics_to_plot is not None:\n",
        "        filtered_data = {}\n",
        "        for name in metrics_data.keys():\n",
        "            for pattern in metrics_to_plot:\n",
        "                if pattern in name:\n",
        "                    filtered_data[name] = metrics_data[name]\n",
        "                    break\n",
        "        metrics_data = filtered_data\n",
        "    \n",
        "    if not metrics_data:\n",
        "        print(\"No metrics to plot!\")\n",
        "        return\n",
        "    \n",
        "    # Separate train and eval metrics\n",
        "    train_metrics = {k: v for k, v in metrics_data.items() if k.startswith('train/')}\n",
        "    eval_metrics = {k: v for k, v in metrics_data.items() if k.startswith('eval/')}\n",
        "    \n",
        "    n_train = len(train_metrics)\n",
        "    n_eval = len(eval_metrics)\n",
        "    n_plots = n_train + (1 if n_eval > 0 else 0)\n",
        "    \n",
        "    if n_plots == 0:\n",
        "        print(\"No metrics to plot!\")\n",
        "        return\n",
        "    \n",
        "    fig, axes = plt.subplots(n_plots, 1, figsize=(10, 3 * n_plots))\n",
        "    if n_plots == 1:\n",
        "        axes = [axes]\n",
        "    \n",
        "    # Plot training metrics\n",
        "    for idx, (name, data) in enumerate(train_metrics.items()):\n",
        "        ax = axes[idx]\n",
        "        ax.plot(data['steps'], data['values'], linewidth=2)\n",
        "        ax.set_xlabel('Step')\n",
        "        ax.set_ylabel('Value')\n",
        "        ax.set_title(name)\n",
        "        ax.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Plot evaluation metrics together\n",
        "    if n_eval > 0:\n",
        "        ax = axes[-1]\n",
        "        for name, data in eval_metrics.items():\n",
        "            ax.plot(data['steps'], data['values'], marker='o', label=name, linewidth=2)\n",
        "        ax.set_xlabel('Step')\n",
        "        ax.set_ylabel('Value')\n",
        "        ax.set_title('Evaluation Metrics')\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    \n",
        "    if save_path is not None:\n",
        "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "        print(f\"Saved plot to {save_path}\")\n",
        "    else:\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "def print_metrics_summary(log_dir: Path):\n",
        "    \"\"\"Print metrics summary.\"\"\"\n",
        "    summary_file = log_dir / 'metrics_summary.json'\n",
        "    \n",
        "    if not summary_file.exists():\n",
        "        print(f\"Summary file not found: {summary_file}\")\n",
        "        return\n",
        "    \n",
        "    with open(summary_file, 'r') as f:\n",
        "        summary = json.load(f)\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"METRICS SUMMARY\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    for name, stats in summary.items():\n",
        "        print(f\"\\n{name}:\")\n",
        "        print(f\"  Final: {stats['final']:.6f}\")\n",
        "        print(f\"  Min:   {stats['min']:.6f}\")\n",
        "        print(f\"  Max:   {stats['max']:.6f}\")\n",
        "        print(f\"  Mean:  {stats['mean']:.6f}\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 80 + \"\\n\")\n",
        "\n",
        "\n",
        "print(\"✓ Visualization utilities loaded.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 8. Usage Examples\n",
        "\n",
        "Now that all components are loaded, here are examples of how to use the system.\n",
        "\n",
        "### Quick Start\n",
        "\n",
        "The simplest way to train a model is to use one of the predefined configurations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example 1: Train a Sparse Koopman Autoencoder on the Duffing Oscillator\n",
        "# This is a quick training run for demonstration (reduce num_steps for faster testing)\n",
        "\n",
        "# Get a predefined configuration\n",
        "cfg = get_config(\"generic_sparse\")\n",
        "\n",
        "# Customize for this experiment\n",
        "cfg.ENV.ENV_NAME = \"duffing\"\n",
        "cfg.TRAIN.NUM_STEPS = 2000  # Reduce for quick demo (use 20000 for full training)\n",
        "cfg.TRAIN.BATCH_SIZE = 256\n",
        "cfg.MODEL.TARGET_SIZE = 64\n",
        "cfg.MODEL.SPARSITY_COEFF = 0.01\n",
        "cfg.SEED = 42\n",
        "\n",
        "# Print configuration summary\n",
        "print(\"Configuration Summary:\")\n",
        "print(f\"  Model: {cfg.MODEL.MODEL_NAME}\")\n",
        "print(f\"  Environment: {cfg.ENV.ENV_NAME}\")\n",
        "print(f\"  Latent dimension: {cfg.MODEL.TARGET_SIZE}\")\n",
        "print(f\"  Training steps: {cfg.TRAIN.NUM_STEPS}\")\n",
        "print(f\"  Batch size: {cfg.TRAIN.BATCH_SIZE}\")\n",
        "print(f\"  Learning rate: {cfg.TRAIN.LR}\")\n",
        "print(f\"  Sparsity coefficient: {cfg.MODEL.SPARSITY_COEFF}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the model\n",
        "# Set run_evaluation=False for faster training; we'll evaluate separately\n",
        "\n",
        "model = train(\n",
        "    cfg=cfg,\n",
        "    log_dir='./runs/demo',\n",
        "    device=DEVICE,\n",
        "    run_evaluation=False,  # We'll evaluate separately\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate the Trained Model\n",
        "\n",
        "After training, we can evaluate the model using different rollout strategies.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run evaluation\n",
        "eval_results = evaluate_model(\n",
        "    model=model,\n",
        "    cfg=cfg,\n",
        "    device=DEVICE,\n",
        "    output_dir=Path('./runs/demo/evaluation'),\n",
        ")\n",
        "\n",
        "# Print evaluation summary\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"EVALUATION RESULTS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "system = cfg.ENV.ENV_NAME\n",
        "if system in eval_results:\n",
        "    system_results = eval_results[system]\n",
        "    print(f\"\\nSystem: {system}\")\n",
        "    \n",
        "    for mode_name, mode_data in system_results[\"modes\"].items():\n",
        "        print(f\"\\n  Mode: {mode_name}\")\n",
        "        for horizon, horizon_data in mode_data[\"horizons\"].items():\n",
        "            mean_mse = horizon_data.get(\"mean\", float(\"nan\"))\n",
        "            print(f\"    Horizon {horizon}: MSE = {mean_mse:.4e}\")\n",
        "    \n",
        "    print(f\"\\n  Best periodic reencoding:\")\n",
        "    for horizon, best in system_results[\"best_periodic\"].items():\n",
        "        print(f\"    Horizon {horizon}: {best['mode']} (MSE = {best['mean']:.4e})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualize Trajectories\n",
        "\n",
        "Let's visualize some predicted trajectories vs ground truth.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize trajectories\n",
        "env = make_env(cfg)\n",
        "vec_env = VectorWrapper(env, batch_size=10)\n",
        "\n",
        "# Generate initial states\n",
        "rng = torch.Generator().manual_seed(999)\n",
        "init_states = vec_env.reset(rng)\n",
        "\n",
        "# Generate ground truth\n",
        "num_steps = 200\n",
        "true_traj = generate_trajectory(vec_env.step, init_states, length=num_steps)\n",
        "\n",
        "# Generate predictions with different reencoding strategies\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    pred_no_reencode = rollout_no_reencode(model, init_states.to(DEVICE), num_steps)\n",
        "    pred_every_step = rollout_every_step_reencode(model, init_states.to(DEVICE), num_steps)\n",
        "\n",
        "# Plot phase portraits\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "# Ground truth\n",
        "ax = axes[0]\n",
        "for i in range(min(5, init_states.shape[0])):\n",
        "    traj = torch.cat([init_states[i:i+1], true_traj[:, i, :]], dim=0).numpy()\n",
        "    ax.plot(traj[:, 0], traj[:, 1], linewidth=1.5, alpha=0.8)\n",
        "ax.set_title(\"Ground Truth\")\n",
        "ax.set_xlabel(\"x1\")\n",
        "ax.set_ylabel(\"x2\")\n",
        "ax.set_aspect(\"equal\", adjustable=\"box\")\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# No reencoding\n",
        "ax = axes[1]\n",
        "for i in range(min(5, init_states.shape[0])):\n",
        "    pred = pred_no_reencode[:, i, :].cpu()\n",
        "    traj = torch.cat([init_states[i:i+1], pred], dim=0).numpy()\n",
        "    ax.plot(traj[:, 0], traj[:, 1], linewidth=1.5, alpha=0.8)\n",
        "ax.set_title(\"Predicted (No Reencoding)\")\n",
        "ax.set_xlabel(\"x1\")\n",
        "ax.set_ylabel(\"x2\")\n",
        "ax.set_aspect(\"equal\", adjustable=\"box\")\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Every-step reencoding\n",
        "ax = axes[2]\n",
        "for i in range(min(5, init_states.shape[0])):\n",
        "    pred = pred_every_step[:, i, :].cpu()\n",
        "    traj = torch.cat([init_states[i:i+1], pred], dim=0).numpy()\n",
        "    ax.plot(traj[:, 0], traj[:, 1], linewidth=1.5, alpha=0.8)\n",
        "ax.set_title(\"Predicted (Every-Step Reencoding)\")\n",
        "ax.set_xlabel(\"x1\")\n",
        "ax.set_ylabel(\"x2\")\n",
        "ax.set_aspect(\"equal\", adjustable=\"box\")\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot Prediction Error Over Time\n",
        "\n",
        "Compare how different rollout strategies accumulate error.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute per-step errors\n",
        "error_no_reencode = torch.norm(pred_no_reencode.cpu() - true_traj, dim=-1).mean(dim=1)\n",
        "error_every_step = torch.norm(pred_every_step.cpu() - true_traj, dim=-1).mean(dim=1)\n",
        "\n",
        "# Plot error curves\n",
        "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
        "steps = np.arange(1, num_steps + 1)\n",
        "\n",
        "ax.plot(steps, error_no_reencode.numpy(), linewidth=2, label=\"No Reencoding\")\n",
        "ax.plot(steps, error_every_step.numpy(), linewidth=2, label=\"Every-Step Reencoding\")\n",
        "\n",
        "ax.set_xlabel(\"Prediction Step\")\n",
        "ax.set_ylabel(\"Mean L2 Error\")\n",
        "ax.set_title(\"Prediction Error vs. Horizon\")\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.set_yscale('log')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nFinal step error (no reencoding): {error_no_reencode[-1]:.4f}\")\n",
        "print(f\"Final step error (every-step): {error_every_step[-1]:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 9. Additional Experiments\n",
        "\n",
        "Here are templates for running other experiments with different configurations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example 2: Train on the Pendulum system\n",
        "# Uncomment and run to train on pendulum\n",
        "\n",
        "# cfg_pendulum = get_config(\"generic_sparse\")\n",
        "# cfg_pendulum.ENV.ENV_NAME = \"pendulum\"\n",
        "# cfg_pendulum.TRAIN.NUM_STEPS = 5000\n",
        "# cfg_pendulum.MODEL.SPARSITY_COEFF = 0.01\n",
        "\n",
        "# model_pendulum = train(\n",
        "#     cfg=cfg_pendulum,\n",
        "#     log_dir='./runs/pendulum',\n",
        "#     device=DEVICE,\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example 3: Train on the Lyapunov Multi-Attractor system\n",
        "# This is a more challenging system with 13 stable equilibria\n",
        "\n",
        "# cfg_lyapunov = get_config(\"generic_sparse\")\n",
        "# cfg_lyapunov.ENV.ENV_NAME = \"lyapunov\"\n",
        "# cfg_lyapunov.TRAIN.NUM_STEPS = 10000\n",
        "# cfg_lyapunov.MODEL.TARGET_SIZE = 64\n",
        "# cfg_lyapunov.MODEL.SPARSITY_COEFF = 0.001\n",
        "# cfg_lyapunov.MODEL.PRED_COEFF = 1.0\n",
        "\n",
        "# model_lyapunov = train(\n",
        "#     cfg=cfg_lyapunov,\n",
        "#     log_dir='./runs/lyapunov',\n",
        "#     device=DEVICE,\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example 4: Train LISTA-based sparse encoder\n",
        "# Uses overcomplete dictionary for sparse coding\n",
        "\n",
        "# cfg_lista = get_config(\"lista\")\n",
        "# cfg_lista.ENV.ENV_NAME = \"duffing\"\n",
        "# cfg_lista.TRAIN.NUM_STEPS = 10000\n",
        "# cfg_lista.MODEL.TARGET_SIZE = 128  # Overcomplete representation\n",
        "\n",
        "# model_lista = train(\n",
        "#     cfg=cfg_lista,\n",
        "#     log_dir='./runs/lista',\n",
        "#     device=DEVICE,\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example 5: Sparsity coefficient sweep\n",
        "# Compare different sparsity regularization strengths\n",
        "\n",
        "# sparsity_coeffs = [0.0, 0.001, 0.01, 0.1]\n",
        "# results = {}\n",
        "\n",
        "# for sparsity in sparsity_coeffs:\n",
        "#     print(f\"\\n{'='*60}\")\n",
        "#     print(f\"Training with sparsity_coeff = {sparsity}\")\n",
        "#     print('='*60)\n",
        "#     \n",
        "#     cfg_sweep = get_config(\"generic_sparse\")\n",
        "#     cfg_sweep.ENV.ENV_NAME = \"duffing\"\n",
        "#     cfg_sweep.TRAIN.NUM_STEPS = 5000\n",
        "#     cfg_sweep.MODEL.SPARSITY_COEFF = sparsity\n",
        "#     \n",
        "#     model_sweep = train(\n",
        "#         cfg=cfg_sweep,\n",
        "#         log_dir=f'./runs/sparsity_sweep_{sparsity}',\n",
        "#         device=DEVICE,\n",
        "#         run_evaluation=False,\n",
        "#     )\n",
        "#     \n",
        "#     # Quick evaluation\n",
        "#     eval_results = evaluate_model(model_sweep, cfg_sweep, device=DEVICE)\n",
        "#     results[sparsity] = eval_results\n",
        "\n",
        "# print(\"\\n\" + \"=\"*60)\n",
        "# print(\"SPARSITY SWEEP SUMMARY\")\n",
        "# print(\"=\"*60)\n",
        "# for sparsity, res in results.items():\n",
        "#     if \"duffing\" in res:\n",
        "#         mse_100 = res[\"duffing\"][\"modes\"][\"every_step\"][\"horizons\"][\"100\"][\"mean\"]\n",
        "#         print(f\"Sparsity {sparsity}: MSE@100 = {mse_100:.4e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Summary\n",
        "\n",
        "This notebook provides a complete, self-contained implementation of Sparse Koopman Autoencoders for learning dynamics of nonlinear systems.\n",
        "\n",
        "### Key Components\n",
        "\n",
        "1. **Configuration System**: Flexible dataclass-based configuration with presets\n",
        "2. **Dynamical Systems**: 6 different environments (Duffing, Pendulum, Lotka-Volterra, Lorenz63, Parabolic, Lyapunov)\n",
        "3. **Models**: GenericKM (MLP encoder) and LISTAKM (sparse LISTA encoder)\n",
        "4. **Training**: AdamW optimizer with separate learning rates for Koopman matrix\n",
        "5. **Evaluation**: Multiple rollout strategies with horizon-wise MSE metrics\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
